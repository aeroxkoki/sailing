# -*- coding: utf-8 -*-
"""
ui.components.forms.data_cleaning.data_cleaning

ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
"""

import streamlit as st
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Callable, Tuple
import altair as alt
from datetime import datetime, timedelta

from sailing_data_processor.data_model.container import GPSDataContainer
from sailing_data_processor.validation.data_validator import DataValidator


class DataCleaning:
    """
    ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
    
    GPSãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼ã¨ä¿®æ­£ã‚’è¡Œã†UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
    """
    
    def __init__(self, 
                 key: str = "data_cleaning", 
                 on_data_cleaned: Optional[Callable[[GPSDataContainer], None]] = None):
        """
        åˆæœŸåŒ–
        
        Parameters
        ----------
        key : str, optional
            ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ä¸€æ„ã®ã‚­ãƒ¼, by default "data_cleaning"
        on_data_cleaned : Optional[Callable[[GPSDataContainer], None]], optional
            ãƒ‡ãƒ¼ã‚¿ä¿®æ­£å®Œäº†æ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°, by default None
        """
        self.key = key
        self.on_data_cleaned = on_data_cleaned
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
        if f"{self.key}_container" not in st.session_state:
            st.session_state[f"{self.key}_container"] = None
        if f"{self.key}_validation_results" not in st.session_state:
            st.session_state[f"{self.key}_validation_results"] = None
        if f"{self.key}_fixed_container" not in st.session_state:
            st.session_state[f"{self.key}_fixed_container"] = None
        if f"{self.key}_fixes" not in st.session_state:
            st.session_state[f"{self.key}_fixes"] = []
        if f"{self.key}_view" not in st.session_state:
            st.session_state[f"{self.key}_view"] = "overview"
        if f"{self.key}_current_issue" not in st.session_state:
            st.session_state[f"{self.key}_current_issue"] = None
        if f"{self.key}_show_fixed" not in st.session_state:
            st.session_state[f"{self.key}_show_fixed"] = False
        if f"{self.key}_auto_fix_applied" not in st.session_state:
            st.session_state[f"{self.key}_auto_fix_applied"] = False
    
    def render(self, container: Optional[GPSDataContainer] = None):
        """
        ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
        
        Parameters
        ----------
        container : Optional[GPSDataContainer], optional
            è¡¨ç¤ºãƒ»æ¤œè¨¼ã™ã‚‹GPSãƒ‡ãƒ¼ã‚¿ã‚³ãƒ³ãƒ†ãƒŠ, by default None
        """
        # ã‚³ãƒ³ãƒ†ãƒŠãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚Œã°ä¿å­˜
        if container is not None:
            st.session_state[f"{self.key}_container"] = container
            # æ–°ã—ã„ã‚³ãƒ³ãƒ†ãƒŠãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã¯çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
            st.session_state[f"{self.key}_validation_results"] = None
            st.session_state[f"{self.key}_fixed_container"] = None
            st.session_state[f"{self.key}_fixes"] = []
            st.session_state[f"{self.key}_view"] = "overview"
            st.session_state[f"{self.key}_current_issue"] = None
            st.session_state[f"{self.key}_show_fixed"] = False
            st.session_state[f"{self.key}_auto_fix_applied"] = False
        
        container = st.session_state.get(f"{self.key}_container")
        
        if container is None:
            st.info("ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã¾ãšãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚")
            return
        
        # ãƒ“ãƒ¥ãƒ¼ã«å¿œã˜ã¦è¡¨ç¤ºã‚’åˆ‡ã‚Šæ›¿ãˆ
        view = st.session_state[f"{self.key}_view"]
        
        if view == "overview":
            self._render_overview()
        elif view == "issue_detail":
            self._render_issue_detail()
        elif view == "fix_report":
            self._render_fix_report()
    
    def _render_overview(self):
        """ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã¨æ¤œè¨¼çµæœã®è¡¨ç¤º"""
        container = st.session_state[f"{self.key}_container"]
        validation_results = st.session_state[f"{self.key}_validation_results"]
        fixed_container = st.session_state.get(f"{self.key}_fixed_container")
        show_fixed = st.session_state.get(f"{self.key}_show_fixed", False)
        
        # è¡¨ç¤ºã™ã‚‹ã‚³ãƒ³ãƒ†ãƒŠã‚’é¸æŠ
        display_container = fixed_container if show_fixed and fixed_container is not None else container
        
        # ã‚¿ãƒ–ã‚’è¨­å®š
        tab1, tab2, tab3 = st.tabs(["ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼", "ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–", "ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"])
        
        with tab1:
            st.header("ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼")
            
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒœã‚¿ãƒ³ï¼ˆã¾ã æ¤œè¨¼ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
            if validation_results is None:
                st.button("ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼", key=f"{self.key}_validate_btn", on_click=self._validate_data)
            else:
                # æ¤œè¨¼çµæœã®è¡¨ç¤º
                self._render_validation_results()
                
                # è‡ªå‹•ä¿®æ­£ãƒœã‚¿ãƒ³ï¼ˆä¿®æ­£ãŒé©ç”¨ã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
                if not st.session_state.get(f"{self.key}_auto_fix_applied", False):
                    st.button("ä¸€èˆ¬çš„ãªå•é¡Œã‚’è‡ªå‹•ä¿®æ­£", key=f"{self.key}_auto_fix_btn", on_click=self._auto_fix_issues)
                
                # ä¿®æ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯åˆ‡ã‚Šæ›¿ãˆãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                if fixed_container is not None:
                    st.checkbox(
                        "ä¿®æ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", 
                        key=f"{self.key}_show_fixed_checkbox",
                        value=show_fixed,
                        on_change=self._toggle_show_fixed
                    )
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒä¿®æ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ãŸã‚‰ã€ä¿®æ­£ã‚’ç¢ºå®šã™ã‚‹ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                if fixed_container is not None and show_fixed:
                    st.button("ä¿®æ­£ã‚’ç¢ºå®š", key=f"{self.key}_confirm_fixes_btn", on_click=self._confirm_fixes)
        
        with tab2:
            st.header("ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–")
            
            # ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–è¡¨ç¤º
            self._render_data_visualization(display_container)
        
        with tab3:
            st.header("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            
            # ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
            self._render_data_preview(display_container)
    
    def _render_validation_results(self):
        """æ¤œè¨¼çµæœã®è¡¨ç¤º"""
        validation_results = st.session_state[f"{self.key}_validation_results"]
        is_valid, results = validation_results
        
        # æ¤œè¨¼çµæœã®ã‚µãƒãƒªãƒ¼
        total_issues = len([r for r in results if not r["is_valid"]])
        error_issues = len([r for r in results if not r["is_valid"] and r["severity"] == "error"])
        warning_issues = len([r for r in results if not r["is_valid"] and r["severity"] == "warning"])
        info_issues = len([r for r in results if not r["is_valid"] and r["severity"] == "info"])
        
        if total_issues == 0:
            st.success("ãƒ‡ãƒ¼ã‚¿ã¯æ¤œè¨¼ã«åˆæ ¼ã—ã¾ã—ãŸã€‚å•é¡Œã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        
        # å•é¡Œã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
        st.write(f"**æ¤œè¨¼çµæœ:** {total_issues}å€‹ã®å•é¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            if error_issues > 0:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {error_issues}ä»¶")
            else:
                st.info("ã‚¨ãƒ©ãƒ¼: 0ä»¶")
        with col2:
            if warning_issues > 0:
                st.warning(f"è­¦å‘Š: {warning_issues}ä»¶")
            else:
                st.info("è­¦å‘Š: 0ä»¶")
        with col3:
            if info_issues > 0:
                st.info(f"æƒ…å ±: {info_issues}ä»¶")
            else:
                st.info("æƒ…å ±: 0ä»¶")
        
        # å•é¡Œãƒªã‚¹ãƒˆã‚’è¡¨ç¤º
        st.subheader("æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ")
        
        issue_number = 0
        for result in results:
            if not result["is_valid"]:
                issue_number += 1
                
                # é‡è¦åº¦ã«å¿œã˜ã¦è‰²ã‚’å¤‰ãˆã‚‹
                if result["severity"] == "error":
                    severity_color = "ğŸ”´"
                elif result["severity"] == "warning":
                    severity_color = "ğŸŸ "
                else:
                    severity_color = "ğŸ”µ"
                
                # å•é¡Œã®è¦ç´„ã‚’ä½œæˆ
                summary = f"{severity_color} **å•é¡Œ #{issue_number}:** {result['rule_name']} - {result['description']}"
                
                # è©³ç´°ã®è¿½åŠ 
                details = result["details"]
                if "error" in details:
                    summary += f"\n\n**ã‚¨ãƒ©ãƒ¼:** {details['error']}"
                elif "message" in details:
                    summary += f"\n\n**ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:** {details['message']}"
                else:
                    # ãƒ«ãƒ¼ãƒ«ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè©³ç´°ã®è¡¨ç¤º
                    rule_name = result["rule_name"]
                    
                    if "Required Columns" in rule_name:
                        missing = details.get("missing_columns", [])
                        if missing:
                            summary += f"\n\n**ä¸è¶³ã‚«ãƒ©ãƒ :** {', '.join(missing)}"
                    elif "Value Range" in rule_name:
                        column = details.get("column", "")
                        count = details.get("out_of_range_count", 0)
                        actual_min = details.get("actual_min")
                        actual_max = details.get("actual_max")
                        
                        summary += f"\n\n**ã‚«ãƒ©ãƒ :** {column}"
                        summary += f"\n**ç¯„å›²å¤–ã®å€¤:** {count}å€‹"
                        if actual_min is not None and actual_max is not None:
                            summary += f"\n**å®Ÿéš›ã®ç¯„å›²:** {actual_min} ã€œ {actual_max}"
                    elif "No Null Values" in rule_name:
                        columns = list(details.get("null_counts", {}).items())
                        null_summary = [f"{col}: {count}å€‹" for col, count in columns if count > 0]
                        
                        if null_summary:
                            summary += f"\n\n**æ¬ æå€¤:** {', '.join(null_summary)}"
                    elif "No Duplicate Timestamps" in rule_name:
                        count = details.get("duplicate_count", 0)
                        summary += f"\n\n**é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—:** {count}å€‹"
                    elif "Spatial Consistency" in rule_name:
                        count = details.get("anomaly_count", 0)
                        max_speed = details.get("max_calculated_speed", 0)
                        
                        summary += f"\n\n**ç•°å¸¸ãªç§»å‹•:** {count}å€‹"
                        summary += f"\n**æœ€å¤§æ¤œå‡ºé€Ÿåº¦:** {max_speed:.1f} ãƒãƒƒãƒˆ"
                    elif "Temporal Consistency" in rule_name:
                        gap_count = details.get("gap_count", 0)
                        reverse_count = details.get("reverse_count", 0)
                        
                        if gap_count > 0:
                            summary += f"\n\n**å¤§ããªæ™‚é–“ã‚®ãƒ£ãƒƒãƒ—:** {gap_count}å€‹"
                        if reverse_count > 0:
                            summary += f"\n**æ™‚é–“é€†è¡Œ:** {reverse_count}å€‹"
                
                # å•é¡Œã®è©³ç´°ã‚’å±•é–‹ã™ã‚‹ã‚¨ã‚¯ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼
                with st.expander(summary, expanded=False):
                    # è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
                    st.write("### è©³ç´°æƒ…å ±")
                    
                    for k, v in details.items():
                        if k not in ["error", "message"]:
                            if isinstance(v, list) and len(v) > 10:
                                st.write(f"**{k}:** {v[:10]} ... (ä»– {len(v) - 10} é …ç›®)")
                            elif isinstance(v, dict) and len(v) > 10:
                                st.write(f"**{k}:** {dict(list(v.items())[:10])} ... (ä»– {len(v) - 10} é …ç›®)")
                            else:
                                st.write(f"**{k}:** {v}")
                    
                    # å•é¡Œã®è©³ç´°ã‚’è¦‹ã‚‹ãƒœã‚¿ãƒ³
                    st.button(
                        "ã“ã®å•é¡Œã‚’è©³ã—ãè¦‹ã‚‹",
                        key=f"{self.key}_view_issue_{issue_number}",
                        on_click=self._view_issue_detail,
                        args=(result,)
                    )
    
    def _render_data_visualization(self, container: GPSDataContainer):
        """ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–è¡¨ç¤º"""
        data = container.data
        
        # ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°ã‚’è¡¨ç¤º
        st.write(f"ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆæ•°: {len(data):,}")
        
        # æ™‚é–“ç¯„å›²ã‚’è¡¨ç¤º
        if len(data) > 0:
            time_range = container.get_time_range()
            st.write(f"é–‹å§‹æ™‚åˆ»: {time_range['start']}")
            st.write(f"çµ‚äº†æ™‚åˆ»: {time_range['end']}")
            st.write(f"æœŸé–“: {time_range['duration_seconds'] / 60:.1f} åˆ†")
        
        # ä½ç½®ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒ—è¡¨ç¤º
        st.subheader("ä½ç½®ãƒ‡ãƒ¼ã‚¿")
        map_data = data[["latitude", "longitude"]].copy()
        st.map(map_data)
        
        # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–
        if len(data) > 0:
            st.subheader("æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿")
            
            # å¯è¦–åŒ–ã™ã‚‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’é¸æŠ
            available_metrics = ["é€Ÿåº¦", "é«˜åº¦", "è·é›¢"]
            metric_cols = {
                "é€Ÿåº¦": "speed",
                "é«˜åº¦": "elevation",
                "è·é›¢": "distance"
            }
            
            # ãƒ‡ãƒ¼ã‚¿ã«å­˜åœ¨ã™ã‚‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç‰¹å®š
            available_metrics = [m for m in available_metrics if metric_cols[m] in data.columns]
            
            if available_metrics:
                selected_metric = st.selectbox(
                    "ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’é¸æŠ:",
                    available_metrics,
                    key=f"{self.key}_metric_select"
                )
                
                # é¸æŠã•ã‚ŒãŸãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ™‚ç³»åˆ—ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ
                metric_col = metric_cols[selected_metric]
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
                chart_data = pd.DataFrame({
                    "æ™‚åˆ»": data["timestamp"],
                    selected_metric: data[metric_col]
                })
                
                # Altairã§ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
                chart = alt.Chart(chart_data).mark_line().encode(
                    x=alt.X('æ™‚åˆ»:T', title='æ™‚åˆ»'),
                    y=alt.Y(f'{selected_metric}:Q', title=selected_metric),
                    tooltip=['æ™‚åˆ»:T', f'{selected_metric}:Q']
                ).interactive()
                
                st.altair_chart(chart, use_container_width=True)
            else:
                st.info("æ™‚ç³»åˆ—ã§å¯è¦–åŒ–ã§ãã‚‹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    def _render_data_preview(self, container: GPSDataContainer):
        """
        ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
        
        å•é¡Œç®‡æ‰€ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆæ©Ÿèƒ½ã‚’è¿½åŠ 
        """
        data = container.data
        
        # æ¤œè¨¼çµæœãŒã‚ã‚‹å ´åˆã¯ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º
        if hasattr(self, "validator") and self.validator and hasattr(self.validator, "validation_results"):
            # å•é¡Œæƒ…å ±ã®å–å¾—
            problem_info = []
            for result in self.validator.validation_results:
                if not result["is_valid"]:
                    # å•é¡Œæƒ…å ±ã‚’è¿½åŠ 
                    for issue in result["issues"]:
                        problem_info.append({
                            "index": issue.get("index", 0),
                            "column": issue.get("column", ""),
                            "problem_type": issue.get("problem_type", "other"),
                            "severity": issue.get("severity", "info"),
                            "description": issue.get("description", ""),
                            "value": issue.get("value", None),
                            "valid_range": issue.get("valid_range", None)
                        })
            
            if problem_info:
                st.subheader("å•é¡Œç®‡æ‰€ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º")
                
                # ãƒã‚¤ãƒ©ã‚¤ãƒˆã®ãŸã‚ã®è‰²å®šç¾©
                highlight_colors = {
                    "missing_data": "#e6ccff",     # è–„ã„ç´«
                    "out_of_range": "#ffcccc",     # è–„ã„èµ¤
                    "duplicates": "#ffffcc",       # è–„ã„é»„
                    "spatial_anomalies": "#ccffcc", # è–„ã„ç·‘
                    "temporal_anomalies": "#ccf2ff" # è–„ã„é’
                }
                
                # é‡è¦åº¦ã”ã¨ã®ä¸é€æ˜åº¦
                severity_opacity = {
                    "error": 1.0,
                    "warning": 0.7,
                    "info": 0.4
                }
                
                # ã‚¹ã‚¿ã‚¤ãƒ«ã‚’é©ç”¨
                styler = data.style
                
                # å•é¡Œã”ã¨ã«ã‚¹ã‚¿ã‚¤ãƒ«ã‚’é©ç”¨
                for problem in problem_info:
                    row_idx = problem["index"]
                    col_name = problem["column"]
                    problem_type = problem.get("problem_type", "other")
                    severity = problem.get("severity", "info")
                    
                    # ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒç¯„å›²å†…ã‹ç¢ºèªï¼‰
                    if row_idx >= 0 and row_idx < len(data) and col_name in data.columns:
                        # å•é¡Œã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè‰²ã‚’å–å¾—
                        color = highlight_colors.get(problem_type, "#f0f0f0")  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯è–„ã„ã‚°ãƒ¬ãƒ¼
                        
                        # é‡è¦åº¦ã«å¿œã˜ãŸä¸é€æ˜åº¦ã‚’é©ç”¨
                        opacity = severity_opacity.get(severity, 0.5)
                        
                        # èƒŒæ™¯è‰²ã¨ã‚¹ã‚¿ã‚¤ãƒ«ã®å®šç¾©
                        background_color = f"rgba({int(int(color[1:3], 16)*opacity)}, {int(int(color[3:5], 16)*opacity)}, {int(int(color[5:7], 16)*opacity)}, {opacity})"
                        
                        # ã‚»ãƒ«ã‚¹ã‚¿ã‚¤ãƒ«ã®é©ç”¨
                        styler = styler.applymap(
                            lambda _: f"background-color: {background_color}; font-weight: bold;",
                            subset=pd.IndexSlice[row_idx:row_idx, col_name:col_name]
                        )
                
                # ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
                st.dataframe(styler, use_container_width=True)
                
                # å•é¡Œã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
                problem_types = {}
                for problem in problem_info:
                    p_type = problem.get("problem_type", "other")
                    if p_type in problem_types:
                        problem_types[p_type] += 1
                    else:
                        problem_types[p_type] = 1
                
                # å•é¡Œã‚¿ã‚¤ãƒ—åˆ¥ã®é›†è¨ˆã‚’è¡¨ç¤º
                st.subheader("å•é¡Œã‚¿ã‚¤ãƒ—åˆ¥ã®é›†è¨ˆ")
                problem_df = pd.DataFrame({
                    "å•é¡Œã‚¿ã‚¤ãƒ—": list(problem_types.keys()),
                    "ä»¶æ•°": list(problem_types.values())
                })
                st.dataframe(problem_df, use_container_width=True)
                
                # å•é¡Œç®‡æ‰€ã¸ã®ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒªãƒ³ã‚¯
                st.info("å•é¡Œç®‡æ‰€ã®è©³ç´°ãªåˆ†æã‚„ä¿®æ­£ã¯ã€ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ã€Œãƒ‡ãƒ¼ã‚¿å•é¡Œã€ã‚¿ãƒ–ã§è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚")
                
            else:
                # å•é¡ŒãŒãªã„å ´åˆã¯é€šå¸¸ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
                st.dataframe(data, use_container_width=True)
        else:
            # æ¤œè¨¼çµæœãŒãªã„å ´åˆã¯é€šå¸¸ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
            st.dataframe(data, use_container_width=True)
        
        # ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„çµ±è¨ˆé‡
        st.subheader("ãƒ‡ãƒ¼ã‚¿ã®è¦ç´„çµ±è¨ˆé‡")
        
        # æ•°å€¤ã‚«ãƒ©ãƒ ã®è¦ç´„çµ±è¨ˆé‡ã‚’è¨ˆç®—
        numeric_cols = data.select_dtypes(include=['number']).columns.tolist()
        if numeric_cols:
            stats = data[numeric_cols].describe().transpose()
            st.dataframe(stats, use_container_width=True)
        else:
            st.info("æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        st.subheader("ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿")
        metadata = container.metadata
        
        for key, value in metadata.items():
            if isinstance(value, (dict, list)) and len(str(value)) > 100:
                with st.expander(f"{key}"):
                    st.write(value)
            else:
                st.write(f"**{key}:** {value}")
    
    def _render_issue_detail(self):
        """å•é¡Œã®è©³ç´°è¡¨ç¤º"""
        issue = st.session_state[f"{self.key}_current_issue"]
        container = st.session_state[f"{self.key}_container"]
        
        if issue is None or container is None:
            st.error("å•é¡Œã®è©³ç´°ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
            st.button("æˆ»ã‚‹", key=f"{self.key}_back_from_detail", on_click=self._go_to_overview)
            return
        
        # å•é¡Œã®ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸã‚¿ã‚¤ãƒˆãƒ«
        rule_name = issue["rule_name"]
        rule_severity = issue["severity"]
        
        # é‡è¦åº¦ã«å¿œã˜ã¦è‰²ã‚’å¤‰ãˆã‚‹
        if rule_severity == "error":
            severity_badge = "ğŸ”´ ã‚¨ãƒ©ãƒ¼"
        elif rule_severity == "warning":
            severity_badge = "ğŸŸ  è­¦å‘Š"
        else:
            severity_badge = "ğŸ”µ æƒ…å ±"
        
        st.header(f"{severity_badge}: {rule_name}")
        st.write(issue["description"])
        
        # è©³ç´°ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º
        details = issue["details"]
        
        # æˆ»ã‚‹ãƒœã‚¿ãƒ³
        st.button("â† æ¤œè¨¼çµæœä¸€è¦§ã«æˆ»ã‚‹", key=f"{self.key}_back_to_overview", on_click=self._go_to_overview)
        
        # ã‚¿ãƒ–ã§ãƒ‡ãƒ¼ã‚¿ã¨å¯è¦–åŒ–ã‚’åˆ†ã‘ã‚‹
        tab1, tab2 = st.tabs(["å•é¡Œã®è©³ç´°", "ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–"])
        
        with tab1:
            # å•é¡Œã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè©³ç´°è¡¨ç¤ºã¨ãƒ•ã‚£ãƒƒã‚¯ã‚¹UI
            if "Required Columns" in rule_name:
                self._render_required_columns_detail(details)
            elif "Value Range" in rule_name:
                self._render_value_range_detail(details)
            elif "No Null Values" in rule_name:
                self._render_null_values_detail(details)
            elif "No Duplicate Timestamps" in rule_name:
                self._render_duplicate_timestamps_detail(details)
            elif "Spatial Consistency" in rule_name:
                self._render_spatial_consistency_detail(details)
            elif "Temporal Consistency" in rule_name:
                self._render_temporal_consistency_detail(details)
            else:
                # æ±ç”¨çš„ãªè©³ç´°è¡¨ç¤º
                for k, v in details.items():
                    if isinstance(v, (list, dict)) and len(str(v)) > 100:
                        with st.expander(f"{k}"):
                            st.write(v)
                    else:
                        st.write(f"**{k}:** {v}")
        
        with tab2:
            # å•é¡Œãƒã‚¤ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–
            if "Value Range" in rule_name:
                self._visualize_value_range_issue(details)
            elif "No Null Values" in rule_name:
                self._visualize_null_values_issue(details)
            elif "No Duplicate Timestamps" in rule_name:
                self._visualize_duplicate_timestamps_issue(details)
            elif "Spatial Consistency" in rule_name:
                self._visualize_spatial_consistency_issue(details)
            elif "Temporal Consistency" in rule_name:
                self._visualize_temporal_consistency_issue(details)
            else:
                st.info("ã“ã®å•é¡Œã‚¿ã‚¤ãƒ—ã«ã¯ç‰¹åˆ¥ãªå¯è¦–åŒ–ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    def _render_required_columns_detail(self, details):
        """å¿…é ˆã‚«ãƒ©ãƒ å•é¡Œã®è©³ç´°è¡¨ç¤º"""
        missing_columns = details.get("missing_columns", [])
        found_columns = details.get("found_columns", [])
        all_columns = details.get("all_columns", [])
        
        st.subheader("å•é¡Œã®è©³ç´°")
        st.error(f"å¿…é ˆã‚«ãƒ©ãƒ ãŒ {len(missing_columns)}å€‹ ä¸è¶³ã—ã¦ã„ã¾ã™")
        
        if missing_columns:
            st.write("**ä¸è¶³ã—ã¦ã„ã‚‹ã‚«ãƒ©ãƒ :**")
            for col in missing_columns:
                st.write(f"- {col}")
        
        if found_columns:
            st.write("**è¦‹ã¤ã‹ã£ãŸã‚«ãƒ©ãƒ :**")
            for col in found_columns:
                st.write(f"- {col}")
        
        st.write("**ã™ã¹ã¦ã®ã‚«ãƒ©ãƒ :**")
        for col in all_columns:
            st.write(f"- {col}")
        
        st.subheader("è§£æ±ºæ–¹æ³•")
        st.info("""
        ã“ã®å•é¡Œã‚’è§£æ±ºã™ã‚‹ã«ã¯ã€ä¸è¶³ã—ã¦ã„ã‚‹ã‚«ãƒ©ãƒ ã‚’ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚
        
        ä¾‹ãˆã°:
        - CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚«ãƒ©ãƒ ãŒå­˜åœ¨ã™ã‚‹ãŒã€åå‰ãŒç•°ãªã‚‹å ´åˆã¯ã€ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ™‚ã«ã‚«ãƒ©ãƒ ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„
        - ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã«å¿…é ˆã‚«ãƒ©ãƒ ãŒãªã„å ´åˆã¯ã€åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
        """)
    
    def _render_value_range_detail(self, details):
        """å€¤ç¯„å›²å•é¡Œã®è©³ç´°è¡¨ç¤º"""
        column = details.get("column", "")
        min_value = details.get("min_value")
        max_value = details.get("max_value")
        out_of_range_count = details.get("out_of_range_count", 0)
        out_of_range_indices = details.get("out_of_range_indices", [])
        actual_min = details.get("actual_min")
        actual_max = details.get("actual_max")
        
        st.subheader("å•é¡Œã®è©³ç´°")
        st.error(f"ã‚«ãƒ©ãƒ  '{column}' ã«ç¯„å›²å¤–ã®å€¤ãŒ {out_of_range_count}å€‹ ã‚ã‚Šã¾ã™")
        
        if min_value is not None and max_value is not None:
            st.write(f"**æœ‰åŠ¹ç¯„å›²:** {min_value} ã‹ã‚‰ {max_value}")
        elif min_value is not None:
            st.write(f"**æœ€å°å€¤:** {min_value}")
        elif max_value is not None:
            st.write(f"**æœ€å¤§å€¤:** {max_value}")
        
        if actual_min is not None and actual_max is not None:
            st.write(f"**å®Ÿéš›ã®ç¯„å›²:** {actual_min} ã‹ã‚‰ {actual_max}")
        
        # å•é¡Œã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
        if out_of_range_indices:
            data = st.session_state[f"{self.key}_container"].data
            problem_data = data.loc[out_of_range_indices]
            
            st.write("**ç¯„å›²å¤–ã®ãƒ‡ãƒ¼ã‚¿:**")
            st.dataframe(problem_data)
        
        # ä¿®æ­£ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.subheader("ä¿®æ­£ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        
        fix_option = st.radio(
            "ä¿®æ­£æ–¹æ³•ã‚’é¸æŠ:",
            ["ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼ˆå¢ƒç•Œå€¤ã«ç½®æ›ï¼‰", "å•é¡Œã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤", "æ‰‹å‹•ã§å€¤ã‚’ç·¨é›†"],
            key=f"{self.key}_value_range_fix_option"
        )
        
        if st.button("é¸æŠã—ãŸæ–¹æ³•ã§ä¿®æ­£", key=f"{self.key}_fix_value_range"):
            if fix_option == "ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ï¼ˆå¢ƒç•Œå€¤ã«ç½®æ›ï¼‰":
                self._fix_value_range_clipping(column, min_value, max_value, out_of_range_indices)
            elif fix_option == "å•é¡Œã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤":
                self._fix_value_range_remove(out_of_range_indices)
            elif fix_option == "æ‰‹å‹•ã§å€¤ã‚’ç·¨é›†":
                st.session_state[f"{self.key}_manual_edit_column"] = column
                st.session_state[f"{self.key}_manual_edit_indices"] = out_of_range_indices
                st.info("ç¾åœ¨ã€æ‰‹å‹•ç·¨é›†æ©Ÿèƒ½ã¯é–‹ç™ºä¸­ã§ã™ã€‚")
                # æ‰‹å‹•ç·¨é›†æ©Ÿèƒ½ã¯å°†æ¥è¿½åŠ 
            
            # ä¿®æ­£å¾Œã«æ¤œè¨¼ã‚’å†å®Ÿè¡Œ
            self._validate_data()
    
    def _render_null_values_detail(self, details):
        """æ¬ æå€¤å•é¡Œã®è©³ç´°è¡¨ç¤º"""
        columns = details.get("columns", [])
        null_counts = details.get("null_counts", {})
        null_indices = details.get("null_indices", {})
        total_null_count = details.get("total_null_count", 0)
        
        st.subheader("å•é¡Œã®è©³ç´°")
        st.error(f"ãƒ‡ãƒ¼ã‚¿ã«æ¬ æå€¤ãŒ {total_null_count}å€‹ ã‚ã‚Šã¾ã™")
        
        if null_counts:
            st.write("**ã‚«ãƒ©ãƒ ã”ã¨ã®æ¬ æå€¤æ•°:**")
            for col, count in null_counts.items():
                if count > 0:
                    st.write(f"- {col}: {count}å€‹")
        
        # å•é¡Œã®ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
        if null_indices:
            data = st.session_state[f"{self.key}_container"].data
            
            all_indices = []
            for col, indices in null_indices.items():
                all_indices.extend(indices)
            
            all_indices = list(set(all_indices))  # é‡è¤‡ã‚’å‰Šé™¤
            
            if all_indices:
                problem_data = data.loc[all_indices]
                
                st.write("**æ¬ æå€¤ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿:**")
                st.dataframe(problem_data)
        
        # ä¿®æ­£ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.subheader("ä¿®æ­£ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        
        # æ¬ æå€¤ã‚’å«ã‚€ã‚«ãƒ©ãƒ ã‚’ç‰¹å®š
        cols_with_nulls = [col for col, count in null_counts.items() if count > 0]
        
        # ã‚«ãƒ©ãƒ é¸æŠï¼ˆè¤‡æ•°é¸æŠå¯èƒ½ï¼‰
        selected_cols = st.multiselect(
            "ä¿®æ­£ã™ã‚‹ã‚«ãƒ©ãƒ ã‚’é¸æŠ:",
            cols_with_nulls,
            default=cols_with_nulls,
            key=f"{self.key}_null_cols_select"
        )
        
        if selected_cols:
            fix_option = st.radio(
                "ä¿®æ­£æ–¹æ³•ã‚’é¸æŠ:",
                ["ç·šå½¢è£œé–“", "å‰ã®å€¤ã§åŸ‹ã‚ã‚‹", "æ¬¡ã®å€¤ã§åŸ‹ã‚ã‚‹", "å¹³å‡å€¤ã§åŸ‹ã‚ã‚‹", "æ¬ æå€¤ã‚’å«ã‚€è¡Œã‚’å‰Šé™¤"],
                key=f"{self.key}_null_fix_option"
            )
            
            if st.button("é¸æŠã—ãŸæ–¹æ³•ã§ä¿®æ­£", key=f"{self.key}_fix_null_values"):
                # é¸æŠã•ã‚ŒãŸã‚«ãƒ©ãƒ ã¨æ–¹æ³•ã§æ¬ æå€¤ã‚’ä¿®æ­£
                if fix_option == "ç·šå½¢è£œé–“":
                    self._fix_null_values_interpolate(selected_cols)
                elif fix_option == "å‰ã®å€¤ã§åŸ‹ã‚ã‚‹":
                    self._fix_null_values_fillna(selected_cols, method="ffill")
                elif fix_option == "æ¬¡ã®å€¤ã§åŸ‹ã‚ã‚‹":
                    self._fix_null_values_fillna(selected_cols, method="bfill")
                elif fix_option == "å¹³å‡å€¤ã§åŸ‹ã‚ã‚‹":
                    self._fix_null_values_fillna(selected_cols, method="mean")
                elif fix_option == "æ¬ æå€¤ã‚’å«ã‚€è¡Œã‚’å‰Šé™¤":
                    self._fix_null_values_dropna(selected_cols)
                
                # ä¿®æ­£å¾Œã«æ¤œè¨¼ã‚’å†å®Ÿè¡Œ
                self._validate_data()
    
    def _render_duplicate_timestamps_detail(self, details):
        """é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å•é¡Œã®è©³ç´°è¡¨ç¤º"""
        duplicate_count = details.get("duplicate_count", 0)
        duplicate_timestamps = details.get("duplicate_timestamps", [])
        duplicate_indices = details.get("duplicate_indices", {})
        
        st.subheader("å•é¡Œã®è©³ç´°")
        st.error(f"é‡è¤‡ã™ã‚‹ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒ {duplicate_count}å€‹ ã‚ã‚Šã¾ã™")
        
        # é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
        if duplicate_indices:
            data = st.session_state[f"{self.key}_container"].data
            
            # é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
            for ts, indices in duplicate_indices.items():
                with st.expander(f"ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {ts} ({len(indices)}å€‹)"):
                    st.dataframe(data.loc[indices])
        
        # ä¿®æ­£ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.subheader("ä¿®æ­£ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        
        fix_option = st.radio(
            "ä¿®æ­£æ–¹æ³•ã‚’é¸æŠ:",
            ["è‡ªå‹•çš„ã«æ™‚é–“ã‚’ãšã‚‰ã™", "å„é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—ã‹ã‚‰1ã¤ã ã‘æ®‹ã™", "ã™ã¹ã¦ã®é‡è¤‡è¡Œã‚’å‰Šé™¤"],
            key=f"{self.key}_duplicate_fix_option"
        )
        
        if st.button("é¸æŠã—ãŸæ–¹æ³•ã§ä¿®æ­£", key=f"{self.key}_fix_duplicates"):
            if fix_option == "è‡ªå‹•çš„ã«æ™‚é–“ã‚’ãšã‚‰ã™":
                self._fix_duplicate_timestamps_offset(duplicate_indices)
            elif fix_option == "å„é‡è¤‡ã‚°ãƒ«ãƒ¼ãƒ—ã‹ã‚‰1ã¤ã ã‘æ®‹ã™":
                self._fix_duplicate_timestamps_keep_first(duplicate_indices)
            elif fix_option == "ã™ã¹ã¦ã®é‡è¤‡è¡Œã‚’å‰Šé™¤":
                self._fix_duplicate_timestamps_remove_all(duplicate_indices)
            
            # ä¿®æ­£å¾Œã«æ¤œè¨¼ã‚’å†å®Ÿè¡Œ
            self._validate_data()
    
    def _render_spatial_consistency_detail(self, details):
        """ç©ºé–“çš„æ•´åˆæ€§å•é¡Œã®è©³ç´°è¡¨ç¤º"""
        anomaly_count = details.get("anomaly_count", 0)
        anomaly_indices = details.get("anomaly_indices", [])
        max_calculated_speed = details.get("max_calculated_speed", 0)
        min_calculated_speed = details.get("min_calculated_speed", 0)
        avg_calculated_speed = details.get("avg_calculated_speed", 0)
        anomaly_details = details.get("anomaly_details", [])
        
        st.subheader("å•é¡Œã®è©³ç´°")
        st.error(f"ç©ºé–“çš„ã«ä¸è‡ªç„¶ãªå‹•ããŒ {anomaly_count}å€‹ æ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
        
        st.write(f"**æœ€å¤§æ¤œå‡ºé€Ÿåº¦:** {max_calculated_speed:.1f} ãƒãƒƒãƒˆ")
        st.write(f"**å¹³å‡é€Ÿåº¦:** {avg_calculated_speed:.1f} ãƒãƒƒãƒˆ")
        st.write(f"**æœ€å°é€Ÿåº¦:** {min_calculated_speed:.1f} ãƒãƒƒãƒˆ")
        
        # ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆã®è©³ç´°ã‚’è¡¨ç¤º
        if anomaly_details:
            st.write("**ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆã®è©³ç´°:**")
            
            for i, detail in enumerate(anomaly_details):
                with st.expander(f"ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆ #{i+1}: {detail.get('speed_knots', 0):.1f} ãƒãƒƒãƒˆ"):
                    for k, v in detail.items():
                        st.write(f"**{k}:** {v}")
        
        # ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
        if anomaly_indices:
            data = st.session_state[f"{self.key}_container"].data
            problem_data = data.iloc[anomaly_indices]
            
            st.write("**ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿:**")
            st.dataframe(problem_data)
        
        # ä¿®æ­£ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.subheader("ä¿®æ­£ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        
        fix_option = st.radio(
            "ä¿®æ­£æ–¹æ³•ã‚’é¸æŠ:",
            ["ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤", "ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆã‚’è£œé–“"],
            key=f"{self.key}_spatial_fix_option"
        )
        
        if st.button("é¸æŠã—ãŸæ–¹æ³•ã§ä¿®æ­£", key=f"{self.key}_fix_spatial"):
            if fix_option == "ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤":
                self._fix_spatial_consistency_remove(anomaly_indices)
            elif fix_option == "ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆã‚’è£œé–“":
                self._fix_spatial_consistency_interpolate(anomaly_indices)
            
            # ä¿®æ­£å¾Œã«æ¤œè¨¼ã‚’å†å®Ÿè¡Œ
            self._validate_data()
    
    def _render_temporal_consistency_detail(self, details):
        """æ™‚é–“çš„æ•´åˆæ€§å•é¡Œã®è©³ç´°è¡¨ç¤º"""
        gap_count = details.get("gap_count", 0)
        gap_indices = details.get("gap_indices", [])
        gap_details = details.get("gap_details", [])
        reverse_count = details.get("reverse_count", 0)
        reverse_indices = details.get("reverse_indices", [])
        reverse_details = details.get("reverse_details", [])
        max_time_gap = details.get("max_time_gap", 0)
        max_actual_gap = details.get("max_actual_gap", 0)
        min_actual_gap = details.get("min_actual_gap", 0)
        avg_actual_gap = details.get("avg_actual_gap", 0)
        
        st.subheader("å•é¡Œã®è©³ç´°")
        
        if gap_count > 0:
            st.error(f"å¤§ããªæ™‚é–“ã‚®ãƒ£ãƒƒãƒ—ãŒ {gap_count}å€‹ æ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
            st.write(f"**è¨±å®¹ã‚®ãƒ£ãƒƒãƒ—:** {max_time_gap:.1f} ç§’")
            st.write(f"**æœ€å¤§ã‚®ãƒ£ãƒƒãƒ—:** {max_actual_gap:.1f} ç§’")
            
            # ã‚®ãƒ£ãƒƒãƒ—ã®è©³ç´°ã‚’è¡¨ç¤º
            if gap_details:
                st.write("**æ™‚é–“ã‚®ãƒ£ãƒƒãƒ—ã®è©³ç´°:**")
                
                for i, detail in enumerate(gap_details):
                    with st.expander(f"ã‚®ãƒ£ãƒƒãƒ— #{i+1}: {detail.get('gap_seconds', 0):.1f} ç§’"):
                        for k, v in detail.items():
                            st.write(f"**{k}:** {v}")
        
        if reverse_count > 0:
            st.error(f"æ™‚é–“ãŒé€†è¡Œã—ã¦ã„ã‚‹ç®‡æ‰€ãŒ {reverse_count}å€‹ æ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
            
            # é€†è¡Œã®è©³ç´°ã‚’è¡¨ç¤º
            if reverse_details:
                st.write("**æ™‚é–“é€†è¡Œã®è©³ç´°:**")
                
                for i, detail in enumerate(reverse_details):
                    with st.expander(f"é€†è¡Œ #{i+1}: {detail.get('diff_seconds', 0):.1f} ç§’"):
                        for k, v in detail.items():
                            st.write(f"**{k}:** {v}")
        
        # ä¿®æ­£ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        st.subheader("ä¿®æ­£ã‚ªãƒ—ã‚·ãƒ§ãƒ³")
        
        if reverse_count > 0:
            st.write("**æ™‚é–“é€†è¡Œã®ä¿®æ­£:**")
            reverse_fix_option = st.radio(
                "é€†è¡Œã—ã¦ã„ã‚‹æ™‚é–“ã®ä¿®æ­£æ–¹æ³•:",
                ["é€†è¡Œã—ã¦ã„ã‚‹ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤", "æ™‚é–“ã‚’è‡ªå‹•ä¿®æ­£"],
                key=f"{self.key}_reverse_fix_option"
            )
            
            if st.button("æ™‚é–“é€†è¡Œã‚’ä¿®æ­£", key=f"{self.key}_fix_reverse"):
                if reverse_fix_option == "é€†è¡Œã—ã¦ã„ã‚‹ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤":
                    self._fix_temporal_consistency_remove_reverse(reverse_indices)
                elif reverse_fix_option == "æ™‚é–“ã‚’è‡ªå‹•ä¿®æ­£":
                    self._fix_temporal_consistency_correct_reverse(reverse_details)
                
                # ä¿®æ­£å¾Œã«æ¤œè¨¼ã‚’å†å®Ÿè¡Œ
                self._validate_data()
        
        if gap_count > 0:
            st.write("**æ™‚é–“ã‚®ãƒ£ãƒƒãƒ—ã®ä¿®æ­£:**")
            gap_fix_option = st.radio(
                "å¤§ããªæ™‚é–“ã‚®ãƒ£ãƒƒãƒ—ã®ä¿®æ­£æ–¹æ³•:",
                ["ãã®ã¾ã¾æ®‹ã™ï¼ˆä¿®æ­£ä¸è¦ï¼‰", "ã‚®ãƒ£ãƒƒãƒ—ã‚’è£œé–“ã™ã‚‹"],
                key=f"{self.key}_gap_fix_option"
            )
            
            if st.button("æ™‚é–“ã‚®ãƒ£ãƒƒãƒ—ã‚’ä¿®æ­£", key=f"{self.key}_fix_gaps"):
                if gap_fix_option == "ã‚®ãƒ£ãƒƒãƒ—ã‚’è£œé–“ã™ã‚‹":
                    self._fix_temporal_consistency_interpolate_gaps(gap_details)
                
                # ä¿®æ­£å¾Œã«æ¤œè¨¼ã‚’å†å®Ÿè¡Œ
                self._validate_data()
    
    def _render_fix_report(self):
        """ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º"""
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        fixed_container = st.session_state.get(f"{self.key}_fixed_container")
        
        if not fixes or fixed_container is None:
            st.error("ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
            st.button("æˆ»ã‚‹", key=f"{self.key}_back_from_report", on_click=self._go_to_overview)
            return
        
        st.header("ãƒ‡ãƒ¼ã‚¿ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆ")
        
        # ä¿®æ­£ã‚µãƒãƒªãƒ¼
        total_fixes = len(fixes)
        st.write(f"**åˆè¨ˆä¿®æ­£æ•°:** {total_fixes}ä»¶")
        
        # ä¿®æ­£ã‚¿ã‚¤ãƒ—åˆ¥ã®é›†è¨ˆ
        fix_types = {}
        for fix in fixes:
            fix_type = fix.get("type", "unknown")
            if fix_type in fix_types:
                fix_types[fix_type] += 1
            else:
                fix_types[fix_type] = 1
        
        # ä¿®æ­£ã‚¿ã‚¤ãƒ—åˆ¥ã®è¡¨ç¤º
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ä¿®æ­£ã‚¿ã‚¤ãƒ—")
            for fix_type, count in fix_types.items():
                st.write(f"- {fix_type}: {count}ä»¶")
        
        with col2:
            # ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®å¤‰åŒ–ã‚’è¨ˆç®—
            original_container = st.session_state.get(f"{self.key}_container")
            if original_container is not None:
                original_size = len(original_container.data)
                fixed_size = len(fixed_container.data)
                size_diff = fixed_size - original_size
                
                st.subheader("ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºã®å¤‰åŒ–")
                st.write(f"ä¿®æ­£å‰: {original_size:,} ãƒã‚¤ãƒ³ãƒˆ")
                st.write(f"ä¿®æ­£å¾Œ: {fixed_size:,} ãƒã‚¤ãƒ³ãƒˆ")
                
                if size_diff < 0:
                    st.write(f"å‰Šæ¸›: {abs(size_diff):,} ãƒã‚¤ãƒ³ãƒˆ ({abs(size_diff) / original_size * 100:.1f}%)")
                elif size_diff > 0:
                    st.write(f"å¢—åŠ : {size_diff:,} ãƒã‚¤ãƒ³ãƒˆ ({size_diff / original_size * 100:.1f}%)")
                else:
                    st.write("å¤‰åŒ–ãªã—")
        
        # ä¿®æ­£è©³ç´°
        st.subheader("ä¿®æ­£ã®è©³ç´°")
        
        for i, fix in enumerate(fixes):
            fix_type = fix.get("type", "unknown")
            description = fix.get("description", "è©³ç´°æƒ…å ±ãªã—")
            
            with st.expander(f"ä¿®æ­£ #{i+1}: {fix_type}"):
                st.write(f"**èª¬æ˜:** {description}")
                
                # ãã®ä»–ã®è©³ç´°ã‚’è¡¨ç¤º
                for k, v in fix.items():
                    if k not in ["type", "description"]:
                        if isinstance(v, (list, dict)) and len(str(v)) > 100:
                            st.write(f"**{k}:**")
                            st.write(v)
                        else:
                            st.write(f"**{k}:** {v}")
        
        # ä¿®æ­£ã®ç¢ºå®šã¾ãŸã¯ç ´æ£„
        col1, col2 = st.columns(2)
        
        with col1:
            st.button("ä¿®æ­£ã‚’ç¢ºå®š", key=f"{self.key}_confirm_report", on_click=self._confirm_fixes)
        
        with col2:
            st.button("ä¿®æ­£ã‚’ç ´æ£„", key=f"{self.key}_discard_report", on_click=self._discard_fixes)
    
    def _visualize_value_range_issue(self, details):
        """å€¤ç¯„å›²å•é¡Œã®å¯è¦–åŒ–"""
        column = details.get("column", "")
        min_value = details.get("min_value")
        max_value = details.get("max_value")
        out_of_range_indices = details.get("out_of_range_indices", [])
        
        if not column or not out_of_range_indices:
            st.info("å¯è¦–åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        data = st.session_state[f"{self.key}_container"].data
        
        # ã‚«ãƒ©ãƒ å€¤ã®åˆ†å¸ƒã‚’ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã§è¡¨ç¤º
        st.subheader(f"ã‚«ãƒ©ãƒ  '{column}' ã®å€¤åˆ†å¸ƒ")
        
        if pd.api.types.is_numeric_dtype(data[column]):
            # ç¯„å›²å¤–ã®å€¤ã‚’ãƒãƒ¼ã‚­ãƒ³ã‚°
            valid_data = data[~data.index.isin(out_of_range_indices)][column]
            invalid_data = data.loc[out_of_range_indices, column]
            
            # ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
            hist_data = pd.DataFrame({
                "å€¤": data[column],
                "çŠ¶æ…‹": ["ç¯„å›²å¤–" if i in out_of_range_indices else "æœ‰åŠ¹" for i in data.index]
            })
            
            # Altairã§ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ä½œæˆ
            chart = alt.Chart(hist_data).mark_bar().encode(
                alt.X('å€¤:Q', bin=alt.Bin(maxbins=50), title=column),
                alt.Y('count()', title='é »åº¦'),
                alt.Color('çŠ¶æ…‹:N', scale=alt.Scale(domain=['æœ‰åŠ¹', 'ç¯„å›²å¤–'], range=['#1f77b4', '#d62728']))
            ).properties(
                width=600,
                height=400
            )
            
            # æœ‰åŠ¹ç¯„å›²ã‚’ç¤ºã™ç¸¦ç·š
            if min_value is not None:
                min_rule = alt.Chart(pd.DataFrame({'min': [min_value]})).mark_rule(color='green').encode(
                    x='min:Q'
                )
                chart = chart + min_rule
            
            if max_value is not None:
                max_rule = alt.Chart(pd.DataFrame({'max': [max_value]})).mark_rule(color='red').encode(
                    x='max:Q'
                )
                chart = chart + max_rule
            
            st.altair_chart(chart, use_container_width=True)
            
            # è¦ç´„çµ±è¨ˆé‡
            st.write("**å€¤ã®çµ±è¨ˆé‡:**")
            st.write(f"å…¨ä½“: æœ€å°={data[column].min()}, æœ€å¤§={data[column].max()}, å¹³å‡={data[column].mean():.2f}")
            
            if not valid_data.empty:
                st.write(f"æœ‰åŠ¹å€¤: æœ€å°={valid_data.min()}, æœ€å¤§={valid_data.max()}, å¹³å‡={valid_data.mean():.2f}")
            
            if not invalid_data.empty:
                st.write(f"ç¯„å›²å¤–å€¤: æœ€å°={invalid_data.min()}, æœ€å¤§={invalid_data.max()}, å¹³å‡={invalid_data.mean():.2f}")
        else:
            st.info(f"ã‚«ãƒ©ãƒ  '{column}' ã¯æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã§ã¯ãªã„ãŸã‚ã€ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
    
    def _visualize_null_values_issue(self, details):
        """æ¬ æå€¤å•é¡Œã®å¯è¦–åŒ–"""
        null_counts = details.get("null_counts", {})
        null_indices = details.get("null_indices", {})
        
        if not null_counts:
            st.info("å¯è¦–åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # æ¬ æå€¤ã®ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
        st.subheader("ã‚«ãƒ©ãƒ ã”ã¨ã®æ¬ æå€¤")
        
        # æ¬ æå€¤ã®å¤šã„ã‚«ãƒ©ãƒ ã§ã‚½ãƒ¼ãƒˆ
        sorted_counts = sorted(null_counts.items(), key=lambda x: x[1], reverse=True)
        count_df = pd.DataFrame(sorted_counts, columns=["ã‚«ãƒ©ãƒ ", "æ¬ æå€¤æ•°"])
        
        # Altairã§ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
        chart = alt.Chart(count_df).mark_bar().encode(
            alt.X('æ¬ æå€¤æ•°:Q', title='æ¬ æå€¤æ•°'),
            alt.Y('ã‚«ãƒ©ãƒ :N', sort='-x', title='ã‚«ãƒ©ãƒ å')
        ).properties(
            width=600,
            height=400
        )
        
        st.altair_chart(chart, use_container_width=True)
        
        # æ¬ æå€¤ã®æ™‚ç³»åˆ—åˆ†å¸ƒ
        if null_indices:
            st.subheader("æ¬ æå€¤ã®æ™‚ç³»åˆ—åˆ†å¸ƒ")
            
            data = st.session_state[f"{self.key}_container"].data
            
            if 'timestamp' in data.columns:
                # æ™‚é–“è»¸ã«æ²¿ã£ãŸæ¬ æå€¤ã®åˆ†å¸ƒã‚’å¯è¦–åŒ–
                time_chunks = pd.date_range(
                    start=data['timestamp'].min(),
                    end=data['timestamp'].max(),
                    periods=20
                )
                
                # æ™‚é–“ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã®æ¬ æå€¤æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
                chunk_counts = {}
                
                for col, indices in null_indices.items():
                    if indices:
                        chunk_counts[col] = []
                        null_times = data.loc[indices, 'timestamp']
                        
                        for i in range(len(time_chunks) - 1):
                            start = time_chunks[i]
                            end = time_chunks[i + 1]
                            count = ((null_times >= start) & (null_times < end)).sum()
                            chunk_counts[col].append({
                                'chunk': i,
                                'start_time': start,
                                'end_time': end,
                                'count': count,
                                'column': col
                            })
                
                # å…¨ã‚«ãƒ©ãƒ ã®æ™‚é–“ãƒãƒ£ãƒ³ã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
                all_chunks = []
                for col, chunks in chunk_counts.items():
                    all_chunks.extend(chunks)
                
                if all_chunks:
                    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                    time_df = pd.DataFrame(all_chunks)
                    
                    # Altairã§ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆ
                    heatmap = alt.Chart(time_df).mark_rect().encode(
                        alt.X('chunk:O', title='æ™‚é–“ãƒãƒ£ãƒ³ã‚¯'),
                        alt.Y('column:N', title='ã‚«ãƒ©ãƒ '),
                        alt.Color('count:Q', scale=alt.Scale(scheme='blues'), title='æ¬ æå€¤æ•°')
                    ).properties(
                        width=600,
                        height=400
                    )
                    
                    st.altair_chart(heatmap, use_container_width=True)
                else:
                    st.info("æ™‚ç³»åˆ—ã§å¯è¦–åŒ–ã§ãã‚‹æ¬ æå€¤ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                st.info("ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚«ãƒ©ãƒ ãŒãªã„ãŸã‚ã€æ™‚ç³»åˆ—åˆ†å¸ƒã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
    
    def _visualize_duplicate_timestamps_issue(self, details):
        """é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å•é¡Œã®å¯è¦–åŒ–"""
        duplicate_timestamps = details.get("duplicate_timestamps", [])
        duplicate_indices = details.get("duplicate_indices", {})
        
        if not duplicate_timestamps:
            st.info("å¯è¦–åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        # é‡è¤‡æ•°ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
        st.subheader("é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®åˆ†å¸ƒ")
        
        # é‡è¤‡æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
        dup_counts = [len(indices) for ts, indices in duplicate_indices.items()]
        
        if dup_counts:
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
            count_df = pd.DataFrame({
                "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—": list(duplicate_indices.keys()),
                "é‡è¤‡æ•°": dup_counts
            })
            
            # Altairã§ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ä½œæˆ
            hist = alt.Chart(count_df).mark_bar().encode(
                alt.X('é‡è¤‡æ•°:Q', bin=True, title='é‡è¤‡æ•°'),
                alt.Y('count()', title='é »åº¦')
            ).properties(
                width=600,
                height=400
            )
            
            st.altair_chart(hist, use_container_width=True)
            
            # é‡è¤‡æ•°ã®çµ±è¨ˆ
            st.write(f"**æœ€å°é‡è¤‡æ•°:** {min(dup_counts)}")
            st.write(f"**æœ€å¤§é‡è¤‡æ•°:** {max(dup_counts)}")
            st.write(f"**å¹³å‡é‡è¤‡æ•°:** {sum(dup_counts) / len(dup_counts):.2f}")
        
        # é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®æ™‚ç³»åˆ—åˆ†å¸ƒ
        if duplicate_timestamps:
            st.subheader("é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®æ™‚ç³»åˆ—åˆ†å¸ƒ")
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ—¥æ™‚ã«å¤‰æ›
            try:
                times = pd.to_datetime(duplicate_timestamps)
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                time_df = pd.DataFrame({
                    "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—": times,
                    "ã‚«ã‚¦ãƒ³ãƒˆ": 1
                })
                
                # Altairã§ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
                timeline = alt.Chart(time_df).mark_circle().encode(
                    alt.X('ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—:T', title='æ™‚é–“'),
                    alt.Y('ã‚«ã‚¦ãƒ³ãƒˆ:Q', title=''),
                    alt.Size('ã‚«ã‚¦ãƒ³ãƒˆ:Q', legend=None)
                ).properties(
                    width=600,
                    height=200
                )
                
                st.altair_chart(timeline, use_container_width=True)
            except:
                st.info("ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ—¥æ™‚å½¢å¼ã«å¤‰æ›ã§ããªã„ãŸã‚ã€æ™‚ç³»åˆ—åˆ†å¸ƒã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
    
    def _visualize_spatial_consistency_issue(self, details):
        """ç©ºé–“çš„æ•´åˆæ€§å•é¡Œã®å¯è¦–åŒ–"""
        anomaly_indices = details.get("anomaly_indices", [])
        anomaly_details = details.get("anomaly_details", [])
        
        if not anomaly_indices:
            st.info("å¯è¦–åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        data = st.session_state[f"{self.key}_container"].data
        
        # é€Ÿåº¦ã®åˆ†å¸ƒã‚’è¡¨ç¤º
        if 'speed' in data.columns:
            st.subheader("é€Ÿåº¦ã®åˆ†å¸ƒ")
            
            # ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆã¨æ­£å¸¸ãƒã‚¤ãƒ³ãƒˆã‚’åˆ†ã‘ã‚‹
            speed_data = pd.DataFrame({
                "é€Ÿåº¦": data['speed'],
                "çŠ¶æ…‹": ["ç•°å¸¸" if i in anomaly_indices else "æ­£å¸¸" for i in range(len(data))]
            })
            
            # Altairã§ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ä½œæˆ
            speed_hist = alt.Chart(speed_data).mark_bar().encode(
                alt.X('é€Ÿåº¦:Q', bin=alt.Bin(maxbins=50), title='é€Ÿåº¦'),
                alt.Y('count()', title='é »åº¦'),
                alt.Color('çŠ¶æ…‹:N', scale=alt.Scale(domain=['æ­£å¸¸', 'ç•°å¸¸'], range=['#1f77b4', '#d62728']))
            ).properties(
                width=600,
                height=400
            )
            
            st.altair_chart(speed_hist, use_container_width=True)
        
        # ä½ç½®ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒ—è¡¨ç¤º
        st.subheader("ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆã®ä½ç½®")
        
        # ãƒãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ä½œæˆ
        map_data = pd.DataFrame({
            "latitude": data['latitude'],
            "longitude": data['longitude'],
            "color": ["red" if i in anomaly_indices else "blue" for i in range(len(data))]
        })
        
        # ãƒãƒƒãƒ—è¡¨ç¤º
        st.map(map_data)
        
        # ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆã®è©³ç´°
        if anomaly_details:
            st.subheader("ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆã®é€Ÿåº¦åˆ†å¸ƒ")
            
            # é€Ÿåº¦ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            speeds = [detail.get('speed_knots', 0) for detail in anomaly_details]
            
            if speeds:
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                speed_df = pd.DataFrame({
                    "ãƒã‚¤ãƒ³ãƒˆ": range(1, len(speeds) + 1),
                    "é€Ÿåº¦": speeds
                })
                
                # Altairã§æ£’ã‚°ãƒ©ãƒ•ä½œæˆ
                speed_chart = alt.Chart(speed_df).mark_bar().encode(
                    alt.X('ãƒã‚¤ãƒ³ãƒˆ:O', title='ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆ'),
                    alt.Y('é€Ÿåº¦:Q', title='é€Ÿåº¦ (ãƒãƒƒãƒˆ)'),
                    alt.Color('é€Ÿåº¦:Q', scale=alt.Scale(scheme='reds'))
                ).properties(
                    width=600,
                    height=400
                )
                
                st.altair_chart(speed_chart, use_container_width=True)
                
                # é€Ÿåº¦ã®çµ±è¨ˆ
                st.write(f"**æœ€å°é€Ÿåº¦:** {min(speeds):.1f} ãƒãƒƒãƒˆ")
                st.write(f"**æœ€å¤§é€Ÿåº¦:** {max(speeds):.1f} ãƒãƒƒãƒˆ")
                st.write(f"**å¹³å‡é€Ÿåº¦:** {sum(speeds) / len(speeds):.1f} ãƒãƒƒãƒˆ")
    
    def _visualize_temporal_consistency_issue(self, details):
        """æ™‚é–“çš„æ•´åˆæ€§å•é¡Œã®å¯è¦–åŒ–"""
        gap_indices = details.get("gap_indices", [])
        gap_details = details.get("gap_details", [])
        reverse_indices = details.get("reverse_indices", [])
        reverse_details = details.get("reverse_details", [])
        
        if not gap_indices and not reverse_indices:
            st.info("å¯è¦–åŒ–ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        data = st.session_state[f"{self.key}_container"].data
        
        # ã‚®ãƒ£ãƒƒãƒ—ã®åˆ†å¸ƒ
        if gap_details:
            st.subheader("æ™‚é–“ã‚®ãƒ£ãƒƒãƒ—ã®åˆ†å¸ƒ")
            
            # ã‚®ãƒ£ãƒƒãƒ—ç§’æ•°ã‚’æŠ½å‡º
            gaps = [detail.get('gap_seconds', 0) for detail in gap_details]
            
            if gaps:
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                gap_df = pd.DataFrame({
                    "ã‚®ãƒ£ãƒƒãƒ—": gaps
                })
                
                # Altairã§ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ä½œæˆ
                gap_hist = alt.Chart(gap_df).mark_bar().encode(
                    alt.X('ã‚®ãƒ£ãƒƒãƒ—:Q', bin=alt.Bin(maxbins=20), title='ã‚®ãƒ£ãƒƒãƒ— (ç§’)'),
                    alt.Y('count()', title='é »åº¦')
                ).properties(
                    width=600,
                    height=300
                )
                
                st.altair_chart(gap_hist, use_container_width=True)
                
                # ã‚®ãƒ£ãƒƒãƒ—ã®çµ±è¨ˆ
                st.write(f"**æœ€å°ã‚®ãƒ£ãƒƒãƒ—:** {min(gaps):.1f} ç§’")
                st.write(f"**æœ€å¤§ã‚®ãƒ£ãƒƒãƒ—:** {max(gaps):.1f} ç§’")
                st.write(f"**å¹³å‡ã‚®ãƒ£ãƒƒãƒ—:** {sum(gaps) / len(gaps):.1f} ç§’")
        
        # é€†è¡Œã®åˆ†å¸ƒ
        if reverse_details:
            st.subheader("æ™‚é–“é€†è¡Œã®åˆ†å¸ƒ")
            
            # é€†è¡Œç§’æ•°ã‚’æŠ½å‡º
            reverses = [abs(detail.get('diff_seconds', 0)) for detail in reverse_details]
            
            if reverses:
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                reverse_df = pd.DataFrame({
                    "é€†è¡Œ": reverses
                })
                
                # Altairã§ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ä½œæˆ
                reverse_hist = alt.Chart(reverse_df).mark_bar().encode(
                    alt.X('é€†è¡Œ:Q', bin=alt.Bin(maxbins=20), title='é€†è¡Œ (ç§’)'),
                    alt.Y('count()', title='é »åº¦')
                ).properties(
                    width=600,
                    height=300
                )
                
                st.altair_chart(reverse_hist, use_container_width=True)
                
                # é€†è¡Œã®çµ±è¨ˆ
                st.write(f"**æœ€å°é€†è¡Œ:** {min(reverses):.1f} ç§’")
                st.write(f"**æœ€å¤§é€†è¡Œ:** {max(reverses):.1f} ç§’")
                st.write(f"**å¹³å‡é€†è¡Œ:** {sum(reverses) / len(reverses):.1f} ç§’")
        
        # æ™‚é–“é–“éš”ã®åˆ†å¸ƒ
        st.subheader("æ™‚é–“é–“éš”ã®åˆ†å¸ƒ")
        
        if 'timestamp' in data.columns and len(data) > 1:
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆ
            sorted_data = data.sort_values('timestamp').copy()
            
            # æ™‚é–“å·®ã‚’è¨ˆç®—
            time_diffs = []
            for i in range(1, len(sorted_data)):
                diff = (sorted_data['timestamp'].iloc[i] - sorted_data['timestamp'].iloc[i-1]).total_seconds()
                time_diffs.append(diff)
            
            if time_diffs:
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›
                diff_df = pd.DataFrame({
                    "æ™‚é–“å·®": time_diffs
                })
                
                # æ¥µç«¯ãªå€¤ã‚’é™¤å¤–ï¼ˆå¯è¦–åŒ–ç”¨ï¼‰
                filtered_diffs = [d for d in time_diffs if d < 600]  # 10åˆ†æœªæº€
                
                if filtered_diffs:
                    filtered_df = pd.DataFrame({
                        "æ™‚é–“å·®": filtered_diffs
                    })
                    
                    # Altairã§ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ä½œæˆ
                    diff_hist = alt.Chart(filtered_df).mark_bar().encode(
                        alt.X('æ™‚é–“å·®:Q', bin=alt.Bin(maxbins=30), title='æ™‚é–“å·® (ç§’)'),
                        alt.Y('count()', title='é »åº¦')
                    ).properties(
                        width=600,
                        height=300
                    )
                    
                    st.altair_chart(diff_hist, use_container_width=True)
                
                # æ™‚é–“å·®ã®çµ±è¨ˆï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ï¼‰
                st.write(f"**æœ€å°æ™‚é–“å·®:** {min(time_diffs):.1f} ç§’")
                st.write(f"**æœ€å¤§æ™‚é–“å·®:** {max(time_diffs):.1f} ç§’")
                st.write(f"**å¹³å‡æ™‚é–“å·®:** {sum(time_diffs) / len(time_diffs):.1f} ç§’")
                st.write(f"**ä¸­å¤®å€¤æ™‚é–“å·®:** {sorted(time_diffs)[len(time_diffs)//2]:.1f} ç§’")
    
    def _fix_value_range_clipping(self, column, min_value, max_value, indices):
        """å€¤ç¯„å›²å•é¡Œã‚’ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã§ä¿®æ­£"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        data = container.data.copy()
        
        # ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã‚’é©ç”¨
        if min_value is not None:
            below_min = data.loc[data.index.isin(indices) & (data[column] < min_value), column]
            data.loc[below_min.index, column] = min_value
        
        if max_value is not None:
            above_max = data.loc[data.index.isin(indices) & (data[column] > max_value), column]
            data.loc[above_max.index, column] = max_value
        
        # ä¿®æ­£çµæœã‚’ä¿å­˜
        fixed_container = GPSDataContainer(data, container.metadata.copy())
        st.session_state[f"{self.key}_fixed_container"] = fixed_container
        
        # ä¿®æ­£ã‚’è¨˜éŒ²
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        fixes.append({
            "type": "value_range_clipping",
            "column": column,
            "min_value": min_value,
            "max_value": max_value,
            "fixed_count": len(indices),
            "description": f"ã‚«ãƒ©ãƒ  '{column}' ã®ç¯„å›²å¤–ã®å€¤ {len(indices)}å€‹ ã‚’ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã—ã¾ã—ãŸ"
        })
        st.session_state[f"{self.key}_fixes"] = fixes
        
        # ä¿®æ­£æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_show_fixed"] = True
    
    def _fix_value_range_remove(self, indices):
        """å€¤ç¯„å›²å•é¡Œã‚’è¡Œå‰Šé™¤ã§ä¿®æ­£"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        data = container.data.copy()
        
        # å•é¡Œã®è¡Œã‚’å‰Šé™¤
        data = data.drop(indices)
        
        # ä¿®æ­£çµæœã‚’ä¿å­˜
        fixed_container = GPSDataContainer(data, container.metadata.copy())
        st.session_state[f"{self.key}_fixed_container"] = fixed_container
        
        # ä¿®æ­£ã‚’è¨˜éŒ²
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        fixes.append({
            "type": "value_range_remove",
            "removed_indices": indices,
            "removed_count": len(indices),
            "description": f"ç¯„å›²å¤–ã®å€¤ã‚’æŒã¤è¡Œ {len(indices)}å€‹ ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
        })
        st.session_state[f"{self.key}_fixes"] = fixes
        
        # ä¿®æ­£æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_show_fixed"] = True
    
    def _fix_null_values_interpolate(self, columns):
        """æ¬ æå€¤ã‚’ç·šå½¢è£œé–“ã§ä¿®æ­£"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        data = container.data.copy()
        
        fixed_count = 0
        for col in columns:
            if col in data.columns:
                null_count = data[col].isnull().sum()
                if null_count > 0:
                    data[col] = data[col].interpolate(method='linear')
                    fixed_count += null_count
        
        # ä¿®æ­£çµæœã‚’ä¿å­˜
        fixed_container = GPSDataContainer(data, container.metadata.copy())
        st.session_state[f"{self.key}_fixed_container"] = fixed_container
        
        # ä¿®æ­£ã‚’è¨˜éŒ²
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        fixes.append({
            "type": "null_values_interpolate",
            "columns": columns,
            "fixed_count": fixed_count,
            "description": f"æ¬ æå€¤ {fixed_count}å€‹ ã‚’ç·šå½¢è£œé–“ã§ä¿®æ­£ã—ã¾ã—ãŸ"
        })
        st.session_state[f"{self.key}_fixes"] = fixes
        
        # ä¿®æ­£æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_show_fixed"] = True
    
    def _fix_null_values_fillna(self, columns, method):
        """æ¬ æå€¤ã‚’åŸ‹ã‚ã‚‹"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        data = container.data.copy()
        
        fixed_count = 0
        for col in columns:
            if col in data.columns:
                null_count = data[col].isnull().sum()
                if null_count > 0:
                    if method == "ffill":
                        data[col] = data[col].fillna(method='ffill')
                        method_name = "å‰ã®å€¤"
                    elif method == "bfill":
                        data[col] = data[col].fillna(method='bfill')
                        method_name = "æ¬¡ã®å€¤"
                    elif method == "mean" and pd.api.types.is_numeric_dtype(data[col]):
                        data[col] = data[col].fillna(data[col].mean())
                        method_name = "å¹³å‡å€¤"
                    else:
                        continue
                    
                    fixed_count += null_count
        
        # ä¿®æ­£çµæœã‚’ä¿å­˜
        fixed_container = GPSDataContainer(data, container.metadata.copy())
        st.session_state[f"{self.key}_fixed_container"] = fixed_container
        
        # ä¿®æ­£ã‚’è¨˜éŒ²
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        fixes.append({
            "type": f"null_values_fill_{method}",
            "columns": columns,
            "fixed_count": fixed_count,
            "description": f"æ¬ æå€¤ {fixed_count}å€‹ ã‚’{method_name}ã§åŸ‹ã‚ã¾ã—ãŸ"
        })
        st.session_state[f"{self.key}_fixes"] = fixes
        
        # ä¿®æ­£æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_show_fixed"] = True
    
    def _fix_null_values_dropna(self, columns):
        """æ¬ æå€¤ã‚’å«ã‚€è¡Œã‚’å‰Šé™¤"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        data = container.data.copy()
        
        # å‰Šé™¤å‰ã®ã‚µã‚¤ã‚º
        original_size = len(data)
        
        # æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã®æ¬ æå€¤ã‚’å«ã‚€è¡Œã‚’å‰Šé™¤
        data = data.dropna(subset=columns)
        
        # å‰Šé™¤ã•ã‚ŒãŸè¡Œæ•°
        removed_count = original_size - len(data)
        
        # ä¿®æ­£çµæœã‚’ä¿å­˜
        fixed_container = GPSDataContainer(data, container.metadata.copy())
        st.session_state[f"{self.key}_fixed_container"] = fixed_container
        
        # ä¿®æ­£ã‚’è¨˜éŒ²
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        fixes.append({
            "type": "null_values_dropna",
            "columns": columns,
            "removed_count": removed_count,
            "description": f"æ¬ æå€¤ã‚’å«ã‚€è¡Œ {removed_count}å€‹ ã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
        })
        st.session_state[f"{self.key}_fixes"] = fixes
        
        # ä¿®æ­£æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_show_fixed"] = True
    
    def _fix_duplicate_timestamps_offset(self, duplicate_indices):
        """é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚ªãƒ•ã‚»ãƒƒãƒˆã§ä¿®æ­£"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        data = container.data.copy()
        
        fixed_count = 0
        for ts, indices in duplicate_indices.items():
            if len(indices) > 1:
                # æœ€åˆã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯å¤‰æ›´ã—ãªã„
                for i, idx in enumerate(indices[1:], 1):
                    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã«å°‘ã—ãšã¤ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’åŠ ãˆã‚‹
                    data.loc[idx, 'timestamp'] = pd.to_datetime(ts) + pd.Timedelta(milliseconds=i)
                    fixed_count += 1
        
        # ä¿®æ­£çµæœã‚’ä¿å­˜
        fixed_container = GPSDataContainer(data, container.metadata.copy())
        st.session_state[f"{self.key}_fixed_container"] = fixed_container
        
        # ä¿®æ­£ã‚’è¨˜éŒ²
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        fixes.append({
            "type": "duplicate_timestamps_offset",
            "fixed_count": fixed_count,
            "description": f"é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ— {fixed_count}å€‹ ã‚’ã‚ªãƒ•ã‚»ãƒƒãƒˆï¼ˆæ™‚é–“ã‚’ãšã‚‰ã™ï¼‰ã§ä¿®æ­£ã—ã¾ã—ãŸ"
        })
        st.session_state[f"{self.key}_fixes"] = fixes
        
        # ä¿®æ­£æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_show_fixed"] = True
    
    def _fix_duplicate_timestamps_keep_first(self, duplicate_indices):
        """é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«1ã¤ã ã‘æ®‹ã—ã¦ä¿®æ­£"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        data = container.data.copy()
        
        # å‰Šé™¤ã™ã‚‹è¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        to_remove = []
        for ts, indices in duplicate_indices.items():
            if len(indices) > 1:
                # æœ€åˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä»¥å¤–ã‚’ã™ã¹ã¦å‰Šé™¤
                to_remove.extend(indices[1:])
        
        # é‡è¤‡è¡Œã‚’å‰Šé™¤
        data = data.drop(to_remove)
        
        # ä¿®æ­£çµæœã‚’ä¿å­˜
        fixed_container = GPSDataContainer(data, container.metadata.copy())
        st.session_state[f"{self.key}_fixed_container"] = fixed_container
        
        # ä¿®æ­£ã‚’è¨˜éŒ²
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        fixes.append({
            "type": "duplicate_timestamps_keep_first",
            "removed_count": len(to_remove),
            "description": f"é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æŒã¤è¡Œ {len(to_remove)}å€‹ ã‚’å‰Šé™¤ã—ã€å„ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‹ã‚‰1ã¤ã ã‘æ®‹ã—ã¾ã—ãŸ"
        })
        st.session_state[f"{self.key}_fixes"] = fixes
        
        # ä¿®æ­£æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_show_fixed"] = True
    
    def _fix_duplicate_timestamps_remove_all(self, duplicate_indices):
        """é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æŒã¤è¡Œã‚’ã™ã¹ã¦å‰Šé™¤"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        data = container.data.copy()
        
        # é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æŒã¤è¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        all_indices = []
        for ts, indices in duplicate_indices.items():
            all_indices.extend(indices)
        
        # é‡è¤‡è¡Œã‚’å‰Šé™¤
        data = data.drop(all_indices)
        
        # ä¿®æ­£çµæœã‚’ä¿å­˜
        fixed_container = GPSDataContainer(data, container.metadata.copy())
        st.session_state[f"{self.key}_fixed_container"] = fixed_container
        
        # ä¿®æ­£ã‚’è¨˜éŒ²
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        fixes.append({
            "type": "duplicate_timestamps_remove_all",
            "removed_count": len(all_indices),
            "description": f"é‡è¤‡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æŒã¤è¡Œ {len(all_indices)}å€‹ ã‚’ã™ã¹ã¦å‰Šé™¤ã—ã¾ã—ãŸ"
        })
        st.session_state[f"{self.key}_fixes"] = fixes
        
        # ä¿®æ­£æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_show_fixed"] = True
    
    def _fix_spatial_consistency_remove(self, anomaly_indices):
        """ç©ºé–“çš„æ•´åˆæ€§å•é¡Œã‚’è¡Œå‰Šé™¤ã§ä¿®æ­£"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        data = container.data.copy()
        
        # å•é¡Œã®ã‚ã‚‹è¡Œã‚’å‰Šé™¤
        original_size = len(data)
        data = data.drop(data.index[anomaly_indices])
        removed_count = original_size - len(data)
        
        # ä¿®æ­£çµæœã‚’ä¿å­˜
        fixed_container = GPSDataContainer(data, container.metadata.copy())
        st.session_state[f"{self.key}_fixed_container"] = fixed_container
        
        # ä¿®æ­£ã‚’è¨˜éŒ²
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        fixes.append({
            "type": "spatial_consistency_remove",
            "removed_count": removed_count,
            "description": f"ç©ºé–“çš„æ•´åˆæ€§ã®ãªã„ {removed_count}å€‹ ã®ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
        })
        st.session_state[f"{self.key}_fixes"] = fixes
        
        # ä¿®æ­£æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_show_fixed"] = True
    
    def _fix_spatial_consistency_interpolate(self, anomaly_indices):
        """ç©ºé–“çš„æ•´åˆæ€§å•é¡Œã‚’è£œé–“ã§ä¿®æ­£"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        data = container.data.copy()
        
        # ç•°å¸¸ãƒã‚¤ãƒ³ãƒˆã‚’ä¸€æ™‚çš„ã«NaNã«ç½®ãæ›ãˆã‚‹
        for i in anomaly_indices:
            if i < len(data):
                data.loc[data.index[i], ['latitude', 'longitude']] = np.nan
        
        # NaNã‚’è£œé–“
        data['latitude'] = data['latitude'].interpolate(method='linear')
        data['longitude'] = data['longitude'].interpolate(method='linear')
        
        # speedã‚«ãƒ©ãƒ ãŒã‚ã‚Œã°å†è¨ˆç®—
        if 'speed' in data.columns:
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆ
            data = data.sort_values('timestamp')
            
            # è·é›¢ã¨æ™‚é–“å·®ã‹ã‚‰é€Ÿåº¦ã‚’å†è¨ˆç®—
            from geopy.distance import great_circle
            
            speeds = []
            for i in range(1, len(data)):
                prev_lat = data['latitude'].iloc[i-1]
                prev_lon = data['longitude'].iloc[i-1]
                curr_lat = data['latitude'].iloc[i]
                curr_lon = data['longitude'].iloc[i]
                
                prev_time = data['timestamp'].iloc[i-1]
                curr_time = data['timestamp'].iloc[i]
                
                distance = great_circle((prev_lat, prev_lon), (curr_lat, curr_lon)).meters
                time_diff = (curr_time - prev_time).total_seconds()
                
                if time_diff > 0:
                    speed = (distance / time_diff) / 0.514444  # m/s to knots
                else:
                    speed = 0
                
                speeds.append(speed)
            
            # æœ€åˆã®è¡Œã®é€Ÿåº¦ã¯2ç•ªç›®ã®å€¤ã‚’ä½¿ç”¨
            speeds.insert(0, speeds[0] if speeds else 0)
            
            # é€Ÿåº¦ã‚’æ›´æ–°
            data['speed'] = speeds
        
        # ä¿®æ­£çµæœã‚’ä¿å­˜
        fixed_container = GPSDataContainer(data, container.metadata.copy())
        st.session_state[f"{self.key}_fixed_container"] = fixed_container
        
        # ä¿®æ­£ã‚’è¨˜éŒ²
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        fixes.append({
            "type": "spatial_consistency_interpolate",
            "fixed_count": len(anomaly_indices),
            "description": f"ç©ºé–“çš„æ•´åˆæ€§ã®ãªã„ {len(anomaly_indices)}å€‹ ã®ãƒã‚¤ãƒ³ãƒˆã‚’è£œé–“ã—ã¾ã—ãŸ"
        })
        st.session_state[f"{self.key}_fixes"] = fixes
        
        # ä¿®æ­£æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_show_fixed"] = True
    
    def _fix_temporal_consistency_remove_reverse(self, reverse_indices):
        """æ™‚é–“çš„é€†è¡Œå•é¡Œã‚’è¡Œå‰Šé™¤ã§ä¿®æ­£"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        data = container.data.copy()
        
        # å•é¡Œã®ã‚ã‚‹è¡Œã‚’å‰Šé™¤
        original_size = len(data)
        data = data.drop(data.index[reverse_indices])
        removed_count = original_size - len(data)
        
        # ä¿®æ­£çµæœã‚’ä¿å­˜
        fixed_container = GPSDataContainer(data, container.metadata.copy())
        st.session_state[f"{self.key}_fixed_container"] = fixed_container
        
        # ä¿®æ­£ã‚’è¨˜éŒ²
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        fixes.append({
            "type": "temporal_consistency_remove_reverse",
            "removed_count": removed_count,
            "description": f"æ™‚é–“çš„ã«é€†è¡Œã™ã‚‹ {removed_count}å€‹ ã®ãƒã‚¤ãƒ³ãƒˆã‚’å‰Šé™¤ã—ã¾ã—ãŸ"
        })
        st.session_state[f"{self.key}_fixes"] = fixes
        
        # ä¿®æ­£æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_show_fixed"] = True
    
    def _fix_temporal_consistency_correct_reverse(self, reverse_details):
        """æ™‚é–“çš„é€†è¡Œå•é¡Œã‚’ä¿®æ­£"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        data = container.data.copy()
        
        fixed_count = 0
        for detail in reverse_details:
            idx = detail.get("original_index")
            prev_ts = detail.get("prev_timestamp")
            curr_ts = detail.get("curr_timestamp")
            
            if idx is not None and prev_ts is not None:
                # ä¿®æ­£ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è¨ˆç®—ï¼ˆå‰ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®1ç§’å¾Œï¼‰
                new_ts = prev_ts + pd.Timedelta(seconds=1)
                
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä¿®æ­£
                data.loc[idx, 'timestamp'] = new_ts
                fixed_count += 1
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆ
        data = data.sort_values('timestamp').reset_index(drop=True)
        
        # ä¿®æ­£çµæœã‚’ä¿å­˜
        fixed_container = GPSDataContainer(data, container.metadata.copy())
        st.session_state[f"{self.key}_fixed_container"] = fixed_container
        
        # ä¿®æ­£ã‚’è¨˜éŒ²
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        fixes.append({
            "type": "temporal_consistency_correct_reverse",
            "fixed_count": fixed_count,
            "description": f"æ™‚é–“çš„ã«é€†è¡Œã™ã‚‹ {fixed_count}å€‹ ã®ãƒã‚¤ãƒ³ãƒˆã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä¿®æ­£ã—ã¾ã—ãŸ"
        })
        st.session_state[f"{self.key}_fixes"] = fixes
        
        # ä¿®æ­£æ¸ˆã¿ãƒ•ãƒ©ã‚°ã‚’ã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_show_fixed"] = True
    
    def _fix_temporal_consistency_interpolate_gaps(self, gap_details):
        """æ™‚é–“ã‚®ãƒ£ãƒƒãƒ—ã‚’è£œé–“ã§ä¿®æ­£"""
        # ã“ã®æ©Ÿèƒ½ã¯ã¾ã å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“
        st.info("æ™‚é–“ã‚®ãƒ£ãƒƒãƒ—ã®è£œé–“æ©Ÿèƒ½ã¯ç¾åœ¨é–‹ç™ºä¸­ã§ã™ã€‚")
    
    def _validate_data(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        
        # ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        validator = DataValidator()
        
        # æ¤œè¨¼å®Ÿè¡Œ
        validation_results = validator.validate(container)
        
        # æ¤œè¨¼çµæœã‚’ä¿å­˜
        st.session_state[f"{self.key}_validation_results"] = validation_results
    
    def _auto_fix_issues(self):
        """ä¸€èˆ¬çš„ãªå•é¡Œã‚’è‡ªå‹•ä¿®æ­£"""
        if f"{self.key}_container" not in st.session_state:
            return
        
        container = st.session_state[f"{self.key}_container"]
        
        # ãƒ‡ãƒ¼ã‚¿ãƒãƒªãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        validator = DataValidator()
        
        # æ¤œè¨¼ã—ã¦è‡ªå‹•ä¿®æ­£
        fixed_container, fixes = validator.fix_common_issues(container)
        
        # ä¿®æ­£çµæœã‚’ä¿å­˜
        st.session_state[f"{self.key}_fixed_container"] = fixed_container
        st.session_state[f"{self.key}_fixes"] = fixes
        st.session_state[f"{self.key}_show_fixed"] = True
        st.session_state[f"{self.key}_auto_fix_applied"] = True
        
        # ä¿®æ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼
        validator = DataValidator()
        validation_results = validator.validate(fixed_container)
        st.session_state[f"{self.key}_validation_results"] = validation_results
    
    def _toggle_show_fixed(self):
        """ä¿®æ­£æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ"""
        st.session_state[f"{self.key}_show_fixed"] = not st.session_state.get(f"{self.key}_show_fixed", False)
    
    def _confirm_fixes(self):
        """ä¿®æ­£ã‚’ç¢ºå®š"""
        if f"{self.key}_fixed_container" not in st.session_state:
            return
        
        fixed_container = st.session_state[f"{self.key}_fixed_container"]
        fixes = st.session_state.get(f"{self.key}_fixes", [])
        
        # å…ƒã®ã‚³ãƒ³ãƒ†ãƒŠã‚’æ›´æ–°
        st.session_state[f"{self.key}_container"] = fixed_container
        
        # ä¿®æ­£æƒ…å ±ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_fixed_container"] = None
        st.session_state[f"{self.key}_fixes"] = []
        st.session_state[f"{self.key}_show_fixed"] = False
        st.session_state[f"{self.key}_auto_fix_applied"] = False
        
        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°ã‚’å®Ÿè¡Œ
        if self.on_data_cleaned:
            self.on_data_cleaned(fixed_container)
        
        # ä¿®æ­£ç¢ºå®šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºï¼ˆå†ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æ™‚ï¼‰
        st.session_state[f"{self.key}_fix_confirmed"] = True
    
    def _discard_fixes(self):
        """ä¿®æ­£ã‚’ç ´æ£„"""
        # ä¿®æ­£æƒ…å ±ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state[f"{self.key}_fixed_container"] = None
        st.session_state[f"{self.key}_fixes"] = []
        st.session_state[f"{self.key}_show_fixed"] = False
        st.session_state[f"{self.key}_auto_fix_applied"] = False
        
        # ä¿®æ­£ç ´æ£„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºï¼ˆå†ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°æ™‚ï¼‰
        st.session_state[f"{self.key}_fix_discarded"] = True
    
    def _view_issue_detail(self, issue):
        """å•é¡Œã®è©³ç´°è¡¨ç¤ºã«åˆ‡ã‚Šæ›¿ãˆ"""
        st.session_state[f"{self.key}_current_issue"] = issue
        st.session_state[f"{self.key}_view"] = "issue_detail"
    
    def _go_to_overview(self):
        """æ¦‚è¦è¡¨ç¤ºã«æˆ»ã‚‹"""
        st.session_state[f"{self.key}_view"] = "overview"
        st.session_state[f"{self.key}_current_issue"] = None
    
    def _go_to_fix_report(self):
        """ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºã«åˆ‡ã‚Šæ›¿ãˆ"""
        st.session_state[f"{self.key}_view"] = "fix_report"
