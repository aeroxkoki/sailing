#!/usr/bin/env python3
"""
エッジケーステスト - セーリング戦略分析システム

このスクリプトは、セーリング戦略分析システムのエッジケースや特殊条件下での
動作を確認し、問題点をより詳細に把握するためのテストを行います。
特にStrategyDetectorのハッシュエラーとAnomalyDetectorのインデックスエラーに焦点を当てます。
"""

import os
import sys
import traceback
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import time
import json
import matplotlib.pyplot as plt
import logging

# プロジェクトルートをPythonパスに追加
project_root = os.path.abspath(os.path.dirname(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# ロギング設定
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('edge_case_tests.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# テスト対象のモジュールをインポート
from sailing_data_processor.strategy.strategy_detector_with_propagation import StrategyDetectorWithPropagation
from sailing_data_processor.anomaly_detector import AnomalyDetector

# 必要に応じて他のモジュールをインポート
from sailing_data_processor.wind_field_fusion_system import WindFieldFusionSystem

def create_low_density_dataset(size=10):
    """極めて少ないポイント数（5-10ポイント）のデータセットを生成"""
    # 基準位置
    base_lat = 35.45
    base_lon = 139.65
    
    # 開始時間
    start_time = datetime.now()
    
    # 基本的なGPSトラック
    latitudes = [base_lat + 0.001 * i for i in range(size)]
    longitudes = [base_lon + 0.001 * i for i in range(size)]
    timestamps = [start_time + timedelta(seconds=i * 60) for i in range(size)]
    
    # 風向風速
    wind_dirs = [90.0 + i * 2 for i in range(size)]
    wind_speeds = [10.0 + 0.1 * i for i in range(size)]
    
    # DataFrameを作成
    return pd.DataFrame({
        'latitude': latitudes,
        'longitude': longitudes,
        'timestamp': timestamps,
        'wind_direction': wind_dirs,
        'wind_speed_knots': wind_speeds
    })

def create_large_dataset(size=10000):
    """極めて多いポイント数（10,000ポイント以上）のデータセットを生成"""
    # 基準位置
    base_lat = 35.45
    base_lon = 139.65
    
    # 開始時間
    start_time = datetime.now()
    
    # 基本的なGPSトラック（サイン波形で変化を持たせる）
    latitudes = [base_lat + 0.0001 * i + 0.0001 * np.sin(i * 0.01) for i in range(size)]
    longitudes = [base_lon + 0.0001 * i + 0.0001 * np.cos(i * 0.02) for i in range(size)]
    timestamps = [start_time + timedelta(seconds=i) for i in range(size)]
    
    # 風向風速（緩やかに変化）
    wind_dirs = [(90.0 + 0.5 * i + 5 * np.sin(i * 0.005)) % 360 for i in range(size)]
    wind_speeds = [10.0 + 0.5 * np.sin(i * 0.01) for i in range(size)]
    
    # DataFrameを作成
    return pd.DataFrame({
        'latitude': latitudes,
        'longitude': longitudes,
        'timestamp': timestamps,
        'wind_direction': wind_dirs,
        'wind_speed_knots': wind_speeds
    })

def create_irregular_time_dataset(size=100):
    """ポイント間の時間間隔が不規則なデータセットを生成"""
    # 基準位置
    base_lat = 35.45
    base_lon = 139.65
    
    # 開始時間
    start_time = datetime.now()
    
    # 不規則な時間間隔（1秒〜30秒）
    time_intervals = np.random.randint(1, 30, size=size)
    timestamps = [start_time]
    
    for i in range(1, size):
        timestamps.append(timestamps[i-1] + timedelta(seconds=time_intervals[i-1]))
    
    # 位置データ
    latitudes = [base_lat + 0.0005 * i for i in range(size)]
    longitudes = [base_lon + 0.0005 * i for i in range(size)]
    
    # 風向風速
    wind_dirs = [90.0 + 0.2 * i for i in range(size)]
    wind_speeds = [10.0 + 0.05 * i for i in range(size)]
    
    # DataFrameを作成
    return pd.DataFrame({
        'latitude': latitudes,
        'longitude': longitudes,
        'timestamp': timestamps,
        'wind_direction': wind_dirs,
        'wind_speed_knots': wind_speeds
    })

def create_outlier_dataset(size=100, outlier_count=5):
    """明らかに外れた値を含むデータセットを生成"""
    # 基準位置
    base_lat = 35.45
    base_lon = 139.65
    
    # 開始時間
    start_time = datetime.now()
    
    # 基本的なGPSトラック
    latitudes = [base_lat + 0.0005 * i for i in range(size)]
    longitudes = [base_lon + 0.0005 * i for i in range(size)]
    timestamps = [start_time + timedelta(seconds=i * 5) for i in range(size)]
    
    # 風向風速
    wind_dirs = [90.0 + 0.2 * i for i in range(size)]
    wind_speeds = [10.0 + 0.05 * i for i in range(size)]
    
    # 外れ値を追加
    for _ in range(outlier_count):
        idx = np.random.randint(1, size - 1)
        outlier_type = np.random.choice(['position', 'wind', 'time'])
        
        if outlier_type == 'position':
            # 位置の外れ値
            latitudes[idx] += np.random.choice([-1, 1]) * 0.1
            longitudes[idx] += np.random.choice([-1, 1]) * 0.1
        elif outlier_type == 'wind':
            # 風向風速の外れ値
            wind_dirs[idx] = (wind_dirs[idx] + 180) % 360  # 反対の風向
            wind_speeds[idx] = wind_speeds[idx] * 3  # 3倍の風速
        else:
            # 時間の外れ値（大きな時間ギャップ）
            timestamps[idx] = timestamps[idx-1] + timedelta(minutes=10)
    
    # DataFrameを作成
    return pd.DataFrame({
        'latitude': latitudes,
        'longitude': longitudes,
        'timestamp': timestamps,
        'wind_direction': wind_dirs,
        'wind_speed_knots': wind_speeds
    })

def create_boundary_dataset(size=100):
    """値が許容範囲の境界に近いデータセットを生成"""
    # 基準位置
    base_lat = 90.0 - 1e-6  # 北極に非常に近い値
    base_lon = 179.999999   # 日付変更線に非常に近い値
    
    # 開始時間
    start_time = datetime.now()
    
    # 基本的なGPSトラック
    latitudes = [base_lat - 1e-8 * i for i in range(size)]  # 徐々に極から遠ざかる
    longitudes = [base_lon - 1e-8 * i for i in range(size)]  # 徐々に日付変更線から遠ざかる
    timestamps = [start_time + timedelta(seconds=i * 5) for i in range(size)]
    
    # 風向風速（境界値）
    wind_dirs = [359.999 - 0.001 * i for i in range(size)]  # 360度に非常に近い値
    wind_speeds = [0.001 + 0.001 * i for i in range(size)]  # 非常に弱い風
    
    # DataFrameを作成
    return pd.DataFrame({
        'latitude': latitudes,
        'longitude': longitudes,
        'timestamp': timestamps,
        'wind_direction': wind_dirs,
        'wind_speed_knots': wind_speeds
    })

def prepare_course_data(df):
    """データフレームからコースデータを準備"""
    # 最初のポイントと最後のポイントで簡易コースを定義
    start_lat = df['latitude'].iloc[0]
    start_lon = df['longitude'].iloc[0]
    end_lat = df['latitude'].iloc[-1]
    end_lon = df['longitude'].iloc[-1]
    
    # データフレームの各ポイントを経路ポイントに変換
    path_points = []
    for _, row in df.iterrows():
        path_point = {
            'lat': row['latitude'],
            'lon': row['longitude'],
            'time': row['timestamp'],
            'course': 0,  # 仮の値
            'speed': 5.0  # 仮の値
        }
        path_points.append(path_point)
    
    # コースデータ構造を構築
    course_data = {
        'start_time': df['timestamp'].iloc[0],
        'legs': [
            {
                'leg_number': 1,
                'is_upwind': True,
                'start_waypoint': {
                    'lat': start_lat,
                    'lon': start_lon,
                    'name': 'Start'
                },
                'end_waypoint': {
                    'lat': end_lat,
                    'lon': end_lon,
                    'name': 'Finish'
                },
                'path': {
                    'path_points': path_points
                }
            }
        ]
    }
    
    return course_data

def prepare_wind_field(df):
    """データフレームから風の場データを準備"""
    # 各ポイントの位置と風情報を風の場データに変換
    wind_field = {
        'wind_data': []
    }
    
    for _, row in df.iterrows():
        wind_point = {
            'latitude': row['latitude'],
            'longitude': row['longitude'],
            'timestamp': row['timestamp'],
            'direction': row['wind_direction'],
            'speed': row['wind_speed_knots']
        }
        wind_field['wind_data'].append(wind_point)
    
    return wind_field

def test_strategy_detector_with_dataset(df, dataset_name):
    """StrategyDetectorをテストする"""
    logger.info(f"=== StrategyDetector テスト: {dataset_name} ===")
    
    try:
        # 必要なデータを準備
        course_data = prepare_course_data(df)
        wind_field = prepare_wind_field(df)
        
        # StrategyDetectorの初期化
        strategy_detector = StrategyDetectorWithPropagation()
        
        # パフォーマンス計測開始
        start_time = time.time()
        
        # 風向シフト検出をテスト
        try:
            logger.debug("風向シフト検出をテスト開始")
            wind_shifts = strategy_detector.detect_wind_shifts_with_propagation(course_data, wind_field)
            logger.info(f"風向シフト検出 成功: {len(wind_shifts)}個のシフトポイントを検出")
        except Exception as e:
            logger.error(f"風向シフト検出 失敗: {str(e)}")
            logger.debug(traceback.format_exc())
        
        # 最適タック検出をテスト
        try:
            logger.debug("最適タック検出をテスト開始")
            tack_points = strategy_detector.detect_optimal_tacks_with_forecast(course_data, wind_field)
            logger.info(f"最適タック検出 成功: {len(tack_points)}個のタックポイントを検出")
        except Exception as e:
            logger.error(f"最適タック検出 失敗: {str(e)}")
            logger.debug(traceback.format_exc())
        
        # パフォーマンス計測終了
        elapsed_time = time.time() - start_time
        logger.info(f"パフォーマンス: 実行時間 {elapsed_time:.2f}秒, データサイズ {len(df)}行")
        
        # メモリ使用量の記録
        import psutil
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        logger.info(f"メモリ使用量: {memory_info.rss / 1024 / 1024:.2f} MB")
        
        return {
            "success": True,
            "execution_time": elapsed_time,
            "memory_usage_mb": memory_info.rss / 1024 / 1024,
            "data_size": len(df)
        }
        
    except Exception as e:
        logger.error(f"StrategyDetectorテスト全体の失敗: {str(e)}")
        logger.debug(traceback.format_exc())
        return {
            "success": False,
            "error": str(e)
        }

def test_anomaly_detector_with_dataset(df, dataset_name):
    """AnomalyDetectorをテストする"""
    logger.info(f"=== AnomalyDetector テスト: {dataset_name} ===")
    
    try:
        # AnomalyDetectorの初期化
        anomaly_detector = AnomalyDetector()
        
        # パフォーマンス計測開始
        start_time = time.time()
        
        # 異常値検出をテスト
        try:
            logger.debug("異常値検出をテスト開始")
            methods = ['z_score', 'speed', 'acceleration', 'distance', 'time_gap']
            detected_df = anomaly_detector.detect_anomalies(df, methods)
            anomaly_count = detected_df['is_anomaly'].sum() if 'is_anomaly' in detected_df.columns else 0
            logger.info(f"異常値検出 成功: {anomaly_count}個の異常値を検出")
        except Exception as e:
            logger.error(f"異常値検出 失敗: {str(e)}")
            logger.debug(traceback.format_exc())
            return {
                "success": False,
                "error": str(e)
            }
        
        # 異常値修正をテスト
        try:
            logger.debug("異常値修正をテスト開始")
            if 'is_anomaly' in detected_df.columns:
                corrected_df = anomaly_detector.fix_anomalies(detected_df, 'linear')
                logger.info(f"異常値修正 成功")
            else:
                logger.warning("異常値検出が失敗したため、修正テストはスキップ")
        except Exception as e:
            logger.error(f"異常値修正 失敗: {str(e)}")
            logger.debug(traceback.format_exc())
        
        # パフォーマンス計測終了
        elapsed_time = time.time() - start_time
        logger.info(f"パフォーマンス: 実行時間 {elapsed_time:.2f}秒, データサイズ {len(df)}行")
        
        # メモリ使用量の記録
        import psutil
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        logger.info(f"メモリ使用量: {memory_info.rss / 1024 / 1024:.2f} MB")
        
        return {
            "success": True,
            "execution_time": elapsed_time,
            "memory_usage_mb": memory_info.rss / 1024 / 1024,
            "data_size": len(df),
            "anomaly_count": anomaly_count
        }
        
    except Exception as e:
        logger.error(f"AnomalyDetectorテスト全体の失敗: {str(e)}")
        logger.debug(traceback.format_exc())
        return {
            "success": False,
            "error": str(e)
        }

def analyze_strategy_detector_error(df, course_data, wind_field):
    """StrategyDetectorのエラーを詳細に分析する"""
    logger.info("=== StrategyDetectorエラー詳細分析 ===")
    
    # StrategyDetectorの初期化
    strategy_detector = StrategyDetectorWithPropagation()
    
    # デバッグ用にインスタンス変数を確認
    logger.debug(f"StrategyDetector設定: {strategy_detector.propagation_config}")
    
    try:
        # エラーが発生する行を特定するためのデバッグ
        logger.debug("_detect_propagation_based_shifts メソッドをデバッグ")
        
        # 元のメソッドのバックアップを保存
        original_method = strategy_detector._detect_propagation_based_shifts
        
        # デバッグ用のラッパーメソッドを定義
        def debug_wrapper(course_data, wind_field):
            logger.debug("_detect_propagation_based_shifts が呼び出されました")
            try:
                # コースデータを確認
                logger.debug(f"コースデータの構造: {json.dumps(course_data, default=str)[:200]}...")
                
                # 風の場データを確認
                logger.debug(f"風の場データの構造: {json.dumps(wind_field, default=str)[:200]}...")
                
                # 各レグを処理
                for leg_idx, leg in enumerate(course_data.get('legs', [])):
                    logger.debug(f"レグ {leg_idx} の処理")
                    
                    # レグパスを取得
                    path_points = leg.get('path', {}).get('path_points', [])
                    
                    if not path_points:
                        logger.debug("path_pointsが空です、次のレグへ")
                        continue
                    
                    # レグタイプ（風上/風下）
                    is_upwind = leg.get('is_upwind', False)
                    logger.debug(f"is_upwind: {is_upwind}")
                    
                    # サンプルポイントの処理
                    sample_rate = max(1, len(path_points) // 10)
                    logger.debug(f"サンプルレート: {sample_rate}, path_points数: {len(path_points)}")
                    
                    for i in range(0, len(path_points), sample_rate):
                        point = path_points[i]
                        logger.debug(f"ポイント {i} を処理中: {json.dumps(point, default=str)}")
                        
                        # 位置と時間を取得
                        position = (point.get('lat', 0), point.get('lon', 0))
                        point_time = point.get('time', 0)
                        
                        # 現在時点での風データ
                        logger.debug(f"位置 {position} と時間 {point_time} での風データを取得")
                        current_wind = strategy_detector._get_wind_at_position_and_time(
                            position, point_time, wind_field
                        )
                        
                        if not current_wind:
                            logger.debug("現在風データが取得できません、次のポイントへ")
                            continue
                        
                        logger.debug(f"取得した風データ: {current_wind}")
                        
                        # ここでエラーが発生する場合は詳細にデバッグ
                        # ...残りのコードは省略
                
                # 元のメソッドを呼び出す
                result = original_method(course_data, wind_field)
                return result
            except Exception as e:
                logger.error(f"エラーが発生しました: {str(e)}")
                logger.debug(traceback.format_exc())
                raise
        
        # 元のメソッドをデバッグ用ラッパーで置き換え
        strategy_detector._detect_propagation_based_shifts = debug_wrapper
        
        # テスト実行
        try:
            wind_shifts = strategy_detector.detect_wind_shifts_with_propagation(course_data, wind_field)
            logger.info(f"風向シフト検出 成功: {len(wind_shifts)}個のシフトポイントを検出")
        except Exception as e:
            logger.error(f"風向シフト検出 失敗: {str(e)}")
            logger.debug(traceback.format_exc())
        
        # メソッドを元に戻す
        strategy_detector._detect_propagation_based_shifts = original_method
        
    except Exception as e:
        logger.error(f"エラー分析中に例外が発生: {str(e)}")
        logger.debug(traceback.format_exc())

def analyze_anomaly_detector_error(df, threshold_search=True):
    """AnomalyDetectorのインデックスエラーを詳細に分析する"""
    logger.info("=== AnomalyDetectorエラー詳細分析 ===")
    
    # AnomalyDetectorの初期化
    anomaly_detector = AnomalyDetector()
    
    try:
        # デバッグ用に設定を確認
        logger.debug(f"AnomalyDetector検出設定: {anomaly_detector.detection_config}")
        logger.debug(f"AnomalyDetector補間設定: {anomaly_detector.interpolation_config}")
        
        # エラーが発生する閾値を特定する
        if threshold_search:
            logger.info("エラーが発生するデータサイズの閾値を特定しています...")
            
            # 2の累乗でデータサイズを増やしながらテスト
            for power in range(1, 15):  # 2から16384
                test_size = 2 ** power
                test_df = create_large_dataset(size=test_size)
                
                logger.debug(f"データサイズ {test_size} でテスト")
                
                try:
                    methods = ['z_score', 'speed', 'acceleration', 'distance', 'time_gap']
                    detected_df = anomaly_detector.detect_anomalies(test_df, methods)
                    logger.debug(f"サイズ {test_size} は成功")
                except Exception as e:
                    logger.error(f"サイズ {test_size} でエラー発生: {str(e)}")
                    logger.debug(traceback.format_exc())
                    
                    # エラー閾値を見つけたらループを抜ける
                    logger.info(f"エラー閾値を特定: サイズ {test_size}")
                    break
        
        # 元のメソッドのバックアップを保存
        original_method = anomaly_detector._detect_by_speed
        
        # デバッグ用のラッパーメソッドを定義
        def debug_wrapper(latitudes, longitudes, timestamps):
            logger.debug("_detect_by_speed が呼び出されました")
            try:
                data_size = len(latitudes)
                logger.debug(f"データサイズ: {data_size}")
                
                # デバッグ情報
                logger.debug(f"latitudes[:5]: {latitudes[:5]}")
                logger.debug(f"longitudes[:5]: {longitudes[:5]}")
                logger.debug(f"timestamps[:5]: {timestamps[:5]}")
                
                # インデックス関連処理を追跡
                logger.debug("速度変化の計算を開始")
                
                # 実際の計算を試み、特にエラーが発生しそうな箇所をデバッグ
                # ...
                
                # 元のメソッドを呼び出す
                result = original_method(latitudes, longitudes, timestamps)
                return result
            except Exception as e:
                logger.error(f"_detect_by_speed でエラーが発生: {str(e)}")
                logger.debug(traceback.format_exc())
                raise
        
        # 元のメソッドをデバッグ用ラッパーで置き換え
        anomaly_detector._detect_by_speed = debug_wrapper
        
        # テスト実行
        try:
            methods = ['z_score', 'speed']
            detected_df = anomaly_detector.detect_anomalies(df, methods)
            logger.info(f"異常値検出 成功")
        except Exception as e:
            logger.error(f"異常値検出 失敗: {str(e)}")
            logger.debug(traceback.format_exc())
        
        # メソッドを元に戻す
        anomaly_detector._detect_by_speed = original_method
        
    except Exception as e:
        logger.error(f"エラー分析中に例外が発生: {str(e)}")
        logger.debug(traceback.format_exc())

def run_performance_tests():
    """パフォーマンステストを実行し、結果をグラフ化する"""
    logger.info("=== パフォーマンステスト ===")
    
    # データサイズのリスト（指数関数的に増加）
    sizes = [10, 50, 100, 500, 1000, 5000, 10000]
    
    # 結果を保存するリスト
    strategy_times = []
    anomaly_times = []
    strategy_memory = []
    anomaly_memory = []
    
    # 各サイズでテスト
    for size in sizes:
        logger.info(f"データサイズ {size} でテスト")
        
        # データセットを生成
        df = create_large_dataset(size=size)
        
        # StrategyDetectorのテスト
        try:
            result = test_strategy_detector_with_dataset(df, f"サイズ{size}")
            if result["success"]:
                strategy_times.append(result["execution_time"])
                strategy_memory.append(result["memory_usage_mb"])
            else:
                strategy_times.append(None)
                strategy_memory.append(None)
        except Exception as e:
            logger.error(f"StrategyDetectorのパフォーマンステストでエラー: {str(e)}")
            strategy_times.append(None)
            strategy_memory.append(None)
        
        # AnomalyDetectorのテスト
        try:
            result = test_anomaly_detector_with_dataset(df, f"サイズ{size}")
            if result["success"]:
                anomaly_times.append(result["execution_time"])
                anomaly_memory.append(result["memory_usage_mb"])
            else:
                anomaly_times.append(None)
                anomaly_memory.append(None)
        except Exception as e:
            logger.error(f"AnomalyDetectorのパフォーマンステストでエラー: {str(e)}")
            anomaly_times.append(None)
            anomaly_memory.append(None)
    
    # 結果をグラフ化
    try:
        # 実行時間のグラフ
        plt.figure(figsize=(10, 6))
        plt.plot(sizes, strategy_times, 'o-', label='StrategyDetector')
        plt.plot(sizes, anomaly_times, 'o-', label='AnomalyDetector')
        plt.xlabel('データサイズ（ポイント数）')
        plt.ylabel('実行時間（秒）')
        plt.title('データサイズと実行時間の関係')
        plt.legend()
        plt.grid(True)
        plt.savefig('performance_time.png')
        
        # メモリ使用量のグラフ
        plt.figure(figsize=(10, 6))
        plt.plot(sizes, strategy_memory, 'o-', label='StrategyDetector')
        plt.plot(sizes, anomaly_memory, 'o-', label='AnomalyDetector')
        plt.xlabel('データサイズ（ポイント数）')
        plt.ylabel('メモリ使用量（MB）')
        plt.title('データサイズとメモリ使用量の関係')
        plt.legend()
        plt.grid(True)
        plt.savefig('performance_memory.png')
        
        logger.info("パフォーマンスグラフを生成しました: performance_time.png, performance_memory.png")
    except Exception as e:
        logger.error(f"グラフ生成中にエラー: {str(e)}")
        logger.debug(traceback.format_exc())
    
    # 結果を保存
    performance_data = {
        "sizes": sizes,
        "strategy_times": strategy_times,
        "anomaly_times": anomaly_times,
        "strategy_memory": strategy_memory,
        "anomaly_memory": anomaly_memory
    }
    
    with open('performance_data.json', 'w') as f:
        json.dump(performance_data, f, indent=2)
    
    logger.info("パフォーマンスデータを保存しました: performance_data.json")

def main():
    """メイン実行関数"""
    logger.info("=== エッジケーステスト開始 ===")
    
    # テスト結果を保存する辞書
    test_results = {}
    
    # 1. 低密度データセットのテスト
    logger.info("1. 低密度データセットのテスト")
    df_low = create_low_density_dataset(size=10)
    course_data_low = prepare_course_data(df_low)
    wind_field_low = prepare_wind_field(df_low)
    
    test_results["low_density"] = {
        "strategy_detector": test_strategy_detector_with_dataset(df_low, "低密度"),
        "anomaly_detector": test_anomaly_detector_with_dataset(df_low, "低密度")
    }
    
    # StrategyDetectorのエラー分析
    analyze_strategy_detector_error(df_low, course_data_low, wind_field_low)
    
    # 2. 大規模データセットのテスト
    logger.info("2. 大規模データセットのテスト")
    df_large = create_large_dataset(size=10000)
    test_results["large"] = {
        "strategy_detector": test_strategy_detector_with_dataset(df_large, "大規模"),
        "anomaly_detector": test_anomaly_detector_with_dataset(df_large, "大規模")
    }
    
    # AnomalyDetectorのエラー分析
    analyze_anomaly_detector_error(df_large)
    
    # 3. 不均一データセットのテスト
    logger.info("3. 不均一データセットのテスト")
    df_irregular = create_irregular_time_dataset(size=100)
    test_results["irregular"] = {
        "strategy_detector": test_strategy_detector_with_dataset(df_irregular, "不均一"),
        "anomaly_detector": test_anomaly_detector_with_dataset(df_irregular, "不均一")
    }
    
    # 4. 異常値データセットのテスト
    logger.info("4. 異常値データセットのテスト")
    df_outlier = create_outlier_dataset(size=100, outlier_count=10)
    test_results["outlier"] = {
        "strategy_detector": test_strategy_detector_with_dataset(df_outlier, "異常値"),
        "anomaly_detector": test_anomaly_detector_with_dataset(df_outlier, "異常値")
    }
    
    # 5. 境界値データセットのテスト
    logger.info("5. 境界値データセットのテスト")
    df_boundary = create_boundary_dataset(size=100)
    test_results["boundary"] = {
        "strategy_detector": test_strategy_detector_with_dataset(df_boundary, "境界値"),
        "anomaly_detector": test_anomaly_detector_with_dataset(df_boundary, "境界値")
    }
    
    # 6. パフォーマンステスト
    logger.info("6. パフォーマンステスト")
    run_performance_tests()
    
    # テスト結果をJSONファイルに保存
    with open('edge_case_test_results.json', 'w') as f:
        json.dump(test_results, f, indent=2, default=str)
    
    logger.info("テスト結果を保存しました: edge_case_test_results.json")
    logger.info("=== エッジケーステスト完了 ===")

if __name__ == "__main__":
    main()
